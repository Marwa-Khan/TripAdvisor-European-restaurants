{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f351a4-1548-4a1a-9df2-d453441ff817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvis in /opt/conda/lib/python3.11/site-packages (0.3.2)\n",
      "Requirement already satisfied: python-louvain in /opt/conda/lib/python3.11/site-packages (0.16)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from pyvis) (8.22.2)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /opt/conda/lib/python3.11/site-packages (from pyvis) (3.1.3)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from pyvis) (4.0.5)\n",
      "Requirement already satisfied: networkx>=1.11 in /opt/conda/lib/python3.11/site-packages (from pyvis) (3.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from python-louvain) (1.26.4)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2>=2.9.6->pyvis) (2.1.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyvis python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257618a9-465f-499b-8764-fef5c23f22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from community import community_louvain\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "from itertools import islice\n",
    "import random\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f266c84-43de-45ea-a3e8-8d6fd08f576d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/sna-project-files/task2_graph.gml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 21\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# data_path=\"tripAdvisor/task2_graph.gml\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# parquet_path= \"tripAdvisor/task2_df.parquet\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_gml\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/sna-project-files/task2_graph.gml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/sna-project-files/task2_df.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded graph: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mG\u001b[38;5;241m.\u001b[39mnumber_of_nodes()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mG\u001b[38;5;241m.\u001b[39mnumber_of_edges()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m edges\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 6:3\u001b[0m, in \u001b[0;36margmap_read_gml_1\u001b[0;34m(path, label, destringizer, backend, **backend_kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/networkx/utils/decorators.py:199\u001b[0m, in \u001b[0;36mopen_file.<locals>._open_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# could be None, or a file handle, in which case the algorithm will deal with it\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m fobj \u001b[38;5;241m=\u001b[39m \u001b[43m_dispatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fobj, \u001b[38;5;28;01mlambda\u001b[39;00m: fobj\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/sna-project-files/task2_graph.gml'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# data_path=\"tripAdvisor/task2_graph.gml\"\n",
    "# parquet_path= \"tripAdvisor/task2_df.parquet\"\n",
    "\n",
    "G = nx.read_gml('/kaggle/input/sna-project-files/task2_graph.gml')\n",
    "df = pd.read_parquet('/kaggle/input/sna-project-files/task2_df.parquet')\n",
    "print(f\"Loaded graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "print(f\"Loaded DataFrame: {len(df)} rows\")\n",
    "\n",
    "print(G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fd0ffb7d-3b36-4682-b530-be19c406dc0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:20.784113Z",
     "iopub.status.busy": "2025-05-05T20:28:20.783816Z",
     "iopub.status.idle": "2025-05-05T20:28:20.788737Z",
     "shell.execute_reply": "2025-05-05T20:28:20.787946Z",
     "shell.execute_reply.started": "2025-05-05T20:28:20.784087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['restaurant_link', 'restaurant_name', 'original_location', 'country',\n",
      "       'region', 'province', 'city', 'address', 'latitude', 'longitude',\n",
      "       'claimed', 'awards', 'popularity_detailed', 'popularity_generic',\n",
      "       'top_tags', 'price_level', 'price_range', 'meals', 'cuisines',\n",
      "       'special_diets', 'features', 'vegetarian_friendly', 'vegan_options',\n",
      "       'gluten_free', 'original_open_hours', 'open_days_per_week',\n",
      "       'open_hours_per_week', 'working_shifts_per_week', 'avg_rating',\n",
      "       'total_reviews_count', 'default_language',\n",
      "       'reviews_count_in_default_language', 'excellent', 'very_good',\n",
      "       'average', 'poor', 'terrible', 'food', 'service', 'value', 'atmosphere',\n",
      "       'keywords'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_parquet('./task2_df.parquet')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "be61bb35-e5df-4260-8520-6e9eaa26823e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:20.789846Z",
     "iopub.status.busy": "2025-05-05T20:28:20.789628Z",
     "iopub.status.idle": "2025-05-05T20:28:20.801703Z",
     "shell.execute_reply": "2025-05-05T20:28:20.801059Z",
     "shell.execute_reply.started": "2025-05-05T20:28:20.789831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "91460                      #1 of 3 places to eat in Suzette\n",
      "701674         #277 of 458 places to eat in Reggio Calabria\n",
      "389450            #6650 of 10645 places to eat in Barcelona\n",
      "566304                                                 None\n",
      "346212    #11 of 23 places to eat in Santa Lucia de Tira...\n",
      "                                ...                        \n",
      "604106                   #5 of 6 places to eat in Glynneath\n",
      "489262                    #17 of 120 places to eat in Neath\n",
      "772878                  #69 of 148 places to eat in Albenga\n",
      "40406                 #6671 of 18480 places to eat in Paris\n",
      "719098                 #3307 of 12913 places to eat in Rome\n",
      "Name: popularity_generic, Length: 5000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['popularity_generic'].isna().sum())\n",
    "print(df['popularity_generic'])\n",
    "# print(df['total_reviews_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e412ff42-32cf-4813-82dd-a81d9a2d4bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:20.803619Z",
     "iopub.status.busy": "2025-05-05T20:28:20.803436Z",
     "iopub.status.idle": "2025-05-05T20:28:20.831312Z",
     "shell.execute_reply": "2025-05-05T20:28:20.829893Z",
     "shell.execute_reply.started": "2025-05-05T20:28:20.803605Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './task4_centrality.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/1701163412.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 1: Load required files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcentrality_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./task4_centrality.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./task2_df.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded centrality data: {len(centrality_df)} rows\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded restaurant data: {len(df)} rows\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './task4_centrality.csv'"
     ]
    }
   ],
   "source": [
    "# Step 1: Load required files\n",
    "centrality_df = pd.read_csv('./task4_centrality.csv')\n",
    "df = pd.read_parquet('./task2_df.parquet')\n",
    "print(f\"Loaded centrality data: {len(centrality_df)} rows\")\n",
    "print(f\"Loaded restaurant data: {len(df)} rows\")\n",
    "print(\"Columns in restaurant data:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f3050-a6ac-4e16-9ef2-9f57cda5a772",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-05T20:28:20.831703Z",
     "iopub.status.idle": "2025-05-05T20:28:20.831981Z",
     "shell.execute_reply": "2025-05-05T20:28:20.831829Z",
     "shell.execute_reply.started": "2025-05-05T20:28:20.831818Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Clean restaurant_name for consistent merging\n",
    "def clean_name(name):\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    # Strip spaces, lowercase, remove special characters, normalize spaces\n",
    "    name = name.strip().lower()\n",
    "    name = re.sub(r'[^a-zA-Z0-9\\s]', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    "\n",
    "centrality_df['restaurant_name'] = centrality_df['restaurant_name'].apply(clean_name)\n",
    "df['restaurant_name'] = df['restaurant_name'].apply(clean_name)\n",
    "\n",
    "# Verify common restaurant_names\n",
    "common_names = len(set(centrality_df['restaurant_name']) & set(df['restaurant_name']))\n",
    "print(f\"Common restaurant_names: {common_names}\")\n",
    "print(\"Sample centrality restaurant_names:\", centrality_df['restaurant_name'].head().tolist())\n",
    "print(\"Sample restaurant dataset names:\", df['restaurant_name'].head().tolist())\n",
    "\n",
    "# Debug unmatched names\n",
    "unmatched = set(centrality_df['restaurant_name']) - set(df['restaurant_name'])\n",
    "if unmatched:\n",
    "    print(\"Sample unmatched centrality names:\", list(unmatched)[:5])\n",
    "\n",
    "# Step 3: Parse popularity_generic into numeric popularity_score (1/rank)\n",
    "def parse_popularity_generic(text):\n",
    "    if pd.isna(text) or text is None or text.lower() == 'none':\n",
    "        return np.nan\n",
    "    # Extract ranking number (e.g., \"#1\" -> 1)\n",
    "    match = re.search(r'#(\\d+)', str(text))\n",
    "    if match:\n",
    "        rank = int(match.group(1))\n",
    "        return 1.0 / rank if rank > 0 else np.nan  # Inverse rank for higher popularity = higher score\n",
    "    return np.nan\n",
    "\n",
    "df['popularity_score'] = df['popularity_generic'].apply(parse_popularity_generic)\n",
    "print(\"\\nSample popularity_generic and parsed popularity_score:\")\n",
    "print(df[['popularity_generic', 'popularity_score']].head(10))\n",
    "print(\"popularity_score NaN count:\", df['popularity_score'].isna().sum())\n",
    "\n",
    "# Step 4: Identify available metrics\n",
    "available_metrics = []\n",
    "for col in ['popularity_score', 'total_reviews_count', 'avg_rating']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        if df[col].isna().sum() < len(df):\n",
    "            available_metrics.append(col)\n",
    "    else:\n",
    "        print(f\"Warning: Column {col} not found in task2_df.parquet\")\n",
    "if not available_metrics:\n",
    "    raise ValueError(\"No valid metrics (popularity_score, total_reviews_count, avg_rating) found\")\n",
    "\n",
    "print(f\"Available metrics: {available_metrics}\")\n",
    "\n",
    "# Step 5: Merge centrality scores with metrics\n",
    "analysis_df = centrality_df[['restaurant_name', 'degree_centrality', 'closeness_centrality', \n",
    "                            'betweenness_centrality', 'eigenvector_centrality']].merge(\n",
    "    df[['restaurant_name'] + available_metrics],\n",
    "    on='restaurant_name',\n",
    "    how='left'\n",
    ")\n",
    "print(f\"Merged data: {len(analysis_df)} rows\")\n",
    "\n",
    "# Step 6: Handle missing or invalid data\n",
    "numeric_columns = ['degree_centrality', 'closeness_centrality', 'betweenness_centrality', \n",
    "                   'eigenvector_centrality'] + available_metrics\n",
    "for col in numeric_columns:\n",
    "    analysis_df[col] = pd.to_numeric(analysis_df[col], errors='coerce')\n",
    "\n",
    "# Check NaN values\n",
    "print(\"\\nNaN counts in numeric columns:\")\n",
    "print(analysis_df[numeric_columns].isna().sum())\n",
    "\n",
    "# Impute NaN for metrics\n",
    "for col in available_metrics:\n",
    "    if col in ['total_reviews_count']:\n",
    "        analysis_df[col] = analysis_df[col].fillna(0)\n",
    "    else:  # popularity_score, avg_rating\n",
    "        analysis_df[col] = analysis_df[col].fillna(analysis_df[col].mean())\n",
    "\n",
    "# Drop rows where all centrality scores are NaN\n",
    "analysis_df = analysis_df.dropna(subset=['degree_centrality', 'eigenvector_centrality'], how='all')\n",
    "print(f\"Data after cleaning: {len(analysis_df)} rows\")\n",
    "\n",
    "# Step 7: Compute Pearson correlations\n",
    "correlation_matrix = analysis_df[numeric_columns].corr(method='pearson')\n",
    "print(\"\\nPearson Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Extract relevant correlations\n",
    "correlations = correlation_matrix.loc[\n",
    "    ['degree_centrality', 'closeness_centrality', 'betweenness_centrality', 'eigenvector_centrality'],\n",
    "    available_metrics\n",
    "]\n",
    "print(\"\\nCentrality vs. Metrics Correlations:\")\n",
    "print(correlations)\n",
    "\n",
    "# Step 8: Interpret results\n",
    "print(\"\\nInterpretations and Implications:\")\n",
    "print(\"Note: popularity_generic was parsed into popularity_score (1/rank, higher score = higher popularity).\")\n",
    "for centrality in ['degree_centrality', 'closeness_centrality', 'betweenness_centrality', 'eigenvector_centrality']:\n",
    "    print(f\"\\n{centrality.replace('_', ' ').title()}:\")\n",
    "    for metric in available_metrics:\n",
    "        corr = correlations.loc[centrality, metric]\n",
    "        strength = \"strong\" if abs(corr) > 0.5 else \"moderate\" if abs(corr) > 0.3 else \"weak\"\n",
    "        direction = \"positive\" if corr > 0 else \"negative\"\n",
    "        print(f\"- Correlation with {metric}: {corr:.4f} ({strength}, {direction})\")\n",
    "        print(f\"  Implication: {centrality.replace('_', ' ').title()} {'is' if abs(corr) > 0.3 else 'is not'} strongly linked to {metric}.\")\n",
    "\n",
    "# Step 9: Visualize relationships (Scatter Plots)\n",
    "n_metrics = len(available_metrics)\n",
    "plt.figure(figsize=(15, 4 * n_metrics))\n",
    "plot_idx = 1\n",
    "for centrality in ['degree_centrality', 'closeness_centrality', 'betweenness_centrality', 'eigenvector_centrality']:\n",
    "    for metric in available_metrics:\n",
    "        plt.subplot(4, n_metrics, plot_idx)\n",
    "        sns.scatterplot(data=analysis_df, x=centrality, y=metric, alpha=0.5)\n",
    "        plt.title(f\"{centrality.replace('_', ' ').title()} vs {metric.replace('_', ' ').title()}\")\n",
    "        plt.xlabel(centrality.replace('_', ' ').title())\n",
    "        plt.ylabel(metric.replace('_', ' ').title())\n",
    "        plot_idx += 1\n",
    "plt.tight_layout()\n",
    "plt.savefig('./task5_scatter_plots.png')\n",
    "print(\"Scatter plots saved to /task5_scatter_plots.png\")\n",
    "\n",
    "# Step 10: Visualize correlation matrix (Heatmap)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlation Matrix: Centrality vs Metrics')\n",
    "plt.savefig('./task5_heatmap.png')\n",
    "print(\"Correlation heatmap saved to /task5_heatmap.png\")\n",
    "\n",
    "# Step 11: Save results\n",
    "correlations.to_csv('./task5_correlations.csv')\n",
    "analysis_df.to_csv('./task5_analysis.csv', index=False)\n",
    "print(\"Saved correlations to /task5_correlations.csv and analysis to /task5_analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf30d5b-25d7-49eb-94fc-a9ecc002829e",
   "metadata": {},
   "source": [
    "### 6. Task\n",
    "## Community Detection (Unweighted)\n",
    "\n",
    "- Apply community detection (e.g., Louvain or Girvan-Newman) on the unweighted network.\n",
    "- Visualize and label resulting communities, analyze their shared features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "46a4938e-7520-4761-b5c2-cb52dfb117dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:25.944417Z",
     "iopub.status.busy": "2025-05-05T20:28:25.944146Z",
     "iopub.status.idle": "2025-05-05T20:28:26.837745Z",
     "shell.execute_reply": "2025-05-05T20:28:26.836962Z",
     "shell.execute_reply.started": "2025-05-05T20:28:25.944391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weighted graph: 4846 nodes, 11238 edges\n",
      "Loaded DataFrame: 5000 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "G_weighted = nx.read_gml('/kaggle/input/sna-project-files/task2_graph.gml')\n",
    "df = pd.read_parquet('/kaggle/input/sna-project-files/task2_df.parquet')\n",
    "print(f\"Loaded weighted graph: {G_weighted.number_of_nodes()} nodes, {G_weighted.number_of_edges()} edges\")\n",
    "print(f\"Loaded DataFrame: {len(df)} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba563f3-3fc2-41b2-a771-95af09d93b5a",
   "metadata": {},
   "source": [
    "### Community Louvain Common Function for Task 6 and 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f5df71a5-adc9-4d76-8d55-fa45b1a46e3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:26.839227Z",
     "iopub.status.busy": "2025-05-05T20:28:26.838997Z",
     "iopub.status.idle": "2025-05-05T20:28:26.844322Z",
     "shell.execute_reply": "2025-05-05T20:28:26.843677Z",
     "shell.execute_reply.started": "2025-05-05T20:28:26.839210Z"
    }
   },
   "outputs": [],
   "source": [
    "def communityLouvainFuc(G, weight=False):\n",
    "    \n",
    "    # communityw = \"community_weighted\" if weight==True else \"community_unweighted\"\n",
    "    \n",
    "    if weight==False:\n",
    "        partition = community_louvain.best_partition(G, random_state=42)\n",
    "    else:\n",
    "        partition = community_louvain.best_partition(G, weight='weight', random_state=42)\n",
    "        \n",
    "    print(f\"Detected {len(set(partition.values()))} communities\")\n",
    "    \n",
    "    # Create DataFrame with community assignments\n",
    "    community_df = pd.DataFrame({\n",
    "        'restaurant_name': list(partition.keys()),\n",
    "        \"community_weighted\" if weight==True else \"community_unweighted\" : list(partition.values())\n",
    "    })\n",
    "    \n",
    "    # Merge with original DataFrame for attributes\n",
    "    community_df = community_df.merge(\n",
    "        df[['restaurant_name', 'city', 'cuisines', 'special_diets', 'features', 'latitude', 'longitude']],\n",
    "        on='restaurant_name',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    return community_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "58e0982f-fd9f-403a-8f20-7c1185817c3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:26.845653Z",
     "iopub.status.busy": "2025-05-05T20:28:26.845145Z",
     "iopub.status.idle": "2025-05-05T20:28:27.262902Z",
     "shell.execute_reply": "2025-05-05T20:28:27.262285Z",
     "shell.execute_reply.started": "2025-05-05T20:28:26.845630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted graph: 4846 nodes, 11238 edges\n",
      "Connected components: 2961\n",
      "Isolated nodes: 2417\n",
      "Detected 2972 communities\n"
     ]
    }
   ],
   "source": [
    "# def safe_literal_eval(val):\n",
    "#     if isinstance(val, str):\n",
    "#         try:\n",
    "#             return ast.literal_eval(val)\n",
    "#         except (ValueError, SyntaxError):\n",
    "#             return []  \n",
    "#     return val\n",
    "\n",
    "# def parse_list_column(col):\n",
    "#     return col.apply(safe_literal_eval)\n",
    "\n",
    "# df['cuisines'] = parse_list_column(df['cuisines'])\n",
    "# df['special_diets'] = parse_list_column(df['special_diets'])\n",
    "# df['features'] = parse_list_column(df['features'])\n",
    "\n",
    "# print(df['cuisines'])\n",
    "\n",
    "\n",
    "# Step 1: Convert to unweighted graph\n",
    "G = G_weighted.copy()\n",
    "for u, v in G.edges():\n",
    "    G[u][v].pop('weight', None)\n",
    "print(f\"Unweighted graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "\n",
    "print(f\"Connected components: {len(list(nx.connected_components(G)))}\")\n",
    "isolated = sum(1 for node in G.nodes() if G.degree(node) == 0)\n",
    "print(f\"Isolated nodes: {isolated}\")\n",
    "\n",
    "\n",
    "# Step 2: Apply Louvain community detection on weighted graph\n",
    "\n",
    "community_unweighted= communityLouvainFuc(G)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cda2ee15-3dbf-4241-98c9-ebe30edb73f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:27.264356Z",
     "iopub.status.busy": "2025-05-05T20:28:27.264150Z",
     "iopub.status.idle": "2025-05-05T20:28:27.285125Z",
     "shell.execute_reply": "2025-05-05T20:28:27.284398Z",
     "shell.execute_reply.started": "2025-05-05T20:28:27.264340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Communities by Size:\n",
      "community_unweighted\n",
      "26     156\n",
      "201    102\n",
      "2       98\n",
      "44      97\n",
      "217     60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Shared Features of Top 3 Communities:\n",
      "\n",
      "Community 26 (156 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 113), ('Helsinki', 4), ('Dresden', 4), ('Dinslaken', 3), ('Weil am Rhein', 2)]\n",
      "\n",
      "Top 5 cuisines: [('European', 25), ('Fast food', 23), ('British', 23), ('Mediterranean', 18), ('Italian', 16)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 49), ('Vegan Options', 31), ('Gluten Free Options', 23), ('Halal', 5)]\n",
      "\n",
      "Top 5 features: [('Seating', 34), ('Wheelchair Accessible', 24), ('Takeout', 23), ('Reservations', 20), ('Table Service', 17)]\n",
      "\n",
      "Community 201 (102 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 140), ('Frankfurt', 13), ('Dusseldorf', 9), ('Hannover', 5), ('Sheffield', 5)]\n",
      "\n",
      "Top 5 cuisines: [('European', 39), ('Fast food', 37), ('British', 34), ('Cafe', 29), ('Mediterranean', 23)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 80), ('Vegan Options', 48), ('Gluten Free Options', 32), ('Halal', 6)]\n",
      "\n",
      "Top 5 features: [('Seating', 41), ('Wheelchair Accessible', 33), ('Takeout', 28), ('Reservations', 22), ('Table Service', 21)]\n",
      "\n",
      "Community 2 (98 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 199), ('Frankfurt', 13), ('Dusseldorf', 9), ('Pamplona', 6), ('Hannover', 5)]\n",
      "\n",
      "Top 5 cuisines: [('Fast food', 51), ('European', 50), ('Mediterranean', 43), ('Cafe', 39), ('British', 36)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 103), ('Vegan Options', 66), ('Gluten Free Options', 44), ('Halal', 6)]\n",
      "\n",
      "Top 5 features: [('Seating', 65), ('Wheelchair Accessible', 52), ('Takeout', 41), ('Table Service', 38), ('Reservations', 35)]\n",
      "\n",
      "Community 44 (97 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 203), ('Paris', 79), ('Frankfurt', 13), ('Dusseldorf', 9), ('Pamplona', 6)]\n",
      "\n",
      "Top 5 cuisines: [('European', 60), ('Fast food', 58), ('Mediterranean', 48), ('French', 46), ('Cafe', 46)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 123), ('Vegan Options', 71), ('Gluten Free Options', 48), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 90), ('Wheelchair Accessible', 58), ('Reservations', 55), ('Takeout', 53), ('Table Service', 52)]\n",
      "\n",
      "Community 217 (60 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 220), ('Paris', 79), ('Milan', 43), ('Frankfurt', 13), ('Dusseldorf', 9)]\n",
      "\n",
      "Top 5 cuisines: [('European', 66), ('Mediterranean', 65), ('Italian', 65), ('Fast food', 60), ('Cafe', 48)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 145), ('Vegan Options', 80), ('Gluten Free Options', 56), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 102), ('Wheelchair Accessible', 67), ('Reservations', 67), ('Table Service', 64), ('Takeout', 56)]\n",
      "\n",
      "Community 99 (50 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 220), ('Paris', 79), ('Madrid', 50), ('Milan', 43), ('Frankfurt', 13)]\n",
      "\n",
      "Top 5 cuisines: [('Mediterranean', 81), ('European', 75), ('Italian', 70), ('Spanish', 63), ('Fast food', 62)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 155), ('Vegan Options', 87), ('Gluten Free Options', 64), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 111), ('Reservations', 75), ('Table Service', 73), ('Wheelchair Accessible', 69), ('Takeout', 59)]\n",
      "\n",
      "Community 30 (44 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 220), ('Paris', 79), ('Madrid', 50), ('Rome', 44), ('Milan', 43)]\n",
      "\n",
      "Top 5 cuisines: [('Italian', 96), ('Mediterranean', 92), ('European', 75), ('Fast food', 65), ('Spanish', 64)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 168), ('Vegan Options', 93), ('Gluten Free Options', 67), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 118), ('Reservations', 83), ('Table Service', 80), ('Wheelchair Accessible', 73), ('Takeout', 66)]\n",
      "\n",
      "Community 5 (30 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 250), ('Paris', 79), ('Madrid', 50), ('Rome', 44), ('Milan', 43)]\n",
      "\n",
      "Top 5 cuisines: [('Italian', 100), ('Mediterranean', 98), ('European', 81), ('Fast food', 70), ('Spanish', 64)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 181), ('Vegan Options', 101), ('Gluten Free Options', 73), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 125), ('Reservations', 85), ('Table Service', 82), ('Wheelchair Accessible', 77), ('Takeout', 69)]\n",
      "\n",
      "Community 63 (28 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 255), ('Paris', 79), ('Madrid', 50), ('Milan', 44), ('Rome', 44)]\n",
      "\n",
      "Top 5 cuisines: [('Italian', 100), ('Mediterranean', 99), ('European', 85), ('Fast food', 73), ('Spanish', 64)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 185), ('Vegan Options', 101), ('Gluten Free Options', 73), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 128), ('Reservations', 87), ('Table Service', 84), ('Wheelchair Accessible', 78), ('Takeout', 72)]\n",
      "\n",
      "Community 89 (26 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 255), ('Paris', 79), ('Madrid', 50), ('Milan', 44), ('Rome', 44)]\n",
      "\n",
      "Top 5 cuisines: [('Mediterranean', 100), ('Italian', 100), ('European', 94), ('Fast food', 73), ('Spanish', 65)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 187), ('Vegan Options', 103), ('Gluten Free Options', 73), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 132), ('Reservations', 92), ('Table Service', 88), ('Wheelchair Accessible', 78), ('Takeout', 76)]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Analyze communities\n",
    "community_unweighted_sizes = community_unweighted['community_unweighted'].value_counts()\n",
    "print(\"\\nTop 5 Communities by Size:\")\n",
    "print(community_unweighted_sizes.head())\n",
    "\n",
    "# Analyze shared features for top 3 communities\n",
    "cuisines=[]\n",
    "cities=[]\n",
    "special_diets=[]\n",
    "features=[]\n",
    "\n",
    "\n",
    "# Safely parse comma-separated cuisines into a list\n",
    "def extract_cuisine_items(column):\n",
    "    all_cuisines = []\n",
    "    for item in column:\n",
    "        if isinstance(item, str):\n",
    "            if item.strip() != '[]':  # exclude empty lists\n",
    "                all_cuisines.extend([c.strip() for c in item.split(',')])\n",
    "        elif isinstance(item, list):  # already parsed\n",
    "            all_cuisines.extend(item)\n",
    "    return all_cuisines\n",
    "\n",
    "# Analysis block\n",
    "\n",
    "top_communities = community_unweighted_sizes.head(10).index\n",
    "print(\"\\nShared Features of Top 3 Communities:\")\n",
    "\n",
    "for comm in top_communities:\n",
    "    comm_df = community_unweighted[community_unweighted['community_unweighted'] == comm]\n",
    "    print(f\"\\nCommunity {comm} ({len(comm_df)} restaurants):\")\n",
    "\n",
    "    cities += extract_cuisine_items(comm_df['city'])\n",
    "    print(f\"\\nTop 5 cities: {Counter(cities).most_common(5)}\")\n",
    "    \n",
    "    cuisines += extract_cuisine_items(comm_df['cuisines'])\n",
    "    \n",
    "    print(f\"\\nTop 5 cuisines: {Counter(cuisines).most_common(5)}\")\n",
    "    \n",
    "    special_diets += extract_cuisine_items(comm_df['special_diets'])\n",
    "    print(f\"\\nTop 5 special_diets: {Counter(special_diets).most_common(5)}\")\n",
    "\n",
    "    features += extract_cuisine_items(comm_df['features'])\n",
    "    print(f\"\\nTop 5 features: {Counter(features).most_common(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8bfe780b-1c99-41d6-8bb2-2f4e026a7fe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:27.285981Z",
     "iopub.status.busy": "2025-05-05T20:28:27.285743Z",
     "iopub.status.idle": "2025-05-05T20:28:27.405962Z",
     "shell.execute_reply": "2025-05-05T20:28:27.405386Z",
     "shell.execute_reply.started": "2025-05-05T20:28:27.285965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top communities subgraph: 0 nodes, 0 edges\n",
      "/kaggle/working/task6_community_graph.html\n",
      "Community visualization saved to /kaggle/working/task6_community_graph.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "G_top = G.subgraph(top_communities)\n",
    "print(f\"\\nTop communities subgraph: {G_top.number_of_nodes()} nodes, {G_top.number_of_edges()} edges\")\n",
    "\n",
    "net = Network(notebook=True, height=\"600px\", width=\"100%\", directed=False, cdn_resources='in_line')\n",
    "net.from_nx(G_top)\n",
    "\n",
    "net = Network(notebook=True, height=\"600px\", width=\"100%\", directed=False, cdn_resources='in_line')\n",
    "\n",
    "# Add nodes with colors and titles\n",
    "colors = ['#FF9999', '#66CC99', '#99CCFF', '#FFCC99', '#CC99FF']\n",
    "for node in G_top.nodes():\n",
    "    comm = partition[node]\n",
    "    city = community_unweighted[community_unweighted['restaurant_name'] == node]['city'].iloc[0]\n",
    "    net.add_node(node, label=node, title=f\"{node}\\nCommunity: {comm}\\nCity: {city}\", color=colors[comm % len(colors)])\n",
    "\n",
    "# Add edges with color\n",
    "for source, target in G_top.edges():\n",
    "    net.add_edge(source, target, color='#888888')\n",
    "\n",
    "net.show_buttons(filter_=['physics'])\n",
    "net.show(\"/kaggle/working/task6_community_graph.html\")\n",
    "print(\"Community visualization saved to /kaggle/working/task6_community_graph.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b4d797a1-7f74-419b-b851-f745bbda49e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:31:19.955466Z",
     "iopub.status.busy": "2025-05-05T20:31:19.954940Z",
     "iopub.status.idle": "2025-05-05T20:31:19.959381Z",
     "shell.execute_reply": "2025-05-05T20:31:19.958643Z",
     "shell.execute_reply.started": "2025-05-05T20:31:19.955445Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import IFrame\n",
    "def showMyHtmlGraph(path):\n",
    "    display(IFrame(path, width=\"100%\", height=\"600px\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4319c790-507c-4757-a6b6-d849d2dff890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:31:22.125271Z",
     "iopub.status.busy": "2025-05-05T20:31:22.124692Z",
     "iopub.status.idle": "2025-05-05T20:31:22.308050Z",
     "shell.execute_reply": "2025-05-05T20:31:22.307446Z",
     "shell.execute_reply.started": "2025-05-05T20:31:22.125249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"task6_community_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x797e634f6ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved community assignments to /kaggle/working/task6_communities.csv and unweighted graph to /kaggle/working/task6_unweighted_graph.gml\n"
     ]
    }
   ],
   "source": [
    "# # Step 6: Save results\n",
    "\n",
    "# display html graph\n",
    "showMyHtmlGraph('task6_community_graph.html')\n",
    "\n",
    "community_unweighted.to_csv('/kaggle/working/task6_communities.csv', index=False)\n",
    "nx.write_gml(G, '/kaggle/working/task6_unweighted_graph.gml')\n",
    "print(\"Saved community assignments to /kaggle/working/task6_communities.csv and unweighted graph to /kaggle/working/task6_unweighted_graph.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278f247-0ecf-416f-9e14-6767d38ba557",
   "metadata": {},
   "source": [
    "### 7. Task\n",
    "## Community Detection (Weighted)\n",
    "\n",
    "- Run the same algorithm on the weighted network.\n",
    "- Compare community structure between the two versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bd25a12e-57df-4db2-9ff5-142ad4d198da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:27.567712Z",
     "iopub.status.busy": "2025-05-05T20:28:27.567511Z",
     "iopub.status.idle": "2025-05-05T20:28:28.697483Z",
     "shell.execute_reply": "2025-05-05T20:28:28.696676Z",
     "shell.execute_reply.started": "2025-05-05T20:28:27.567696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weighted graph: 4846 nodes, 11238 edges\n",
      "Loaded DataFrame: 5000 rows\n"
     ]
    }
   ],
   "source": [
    "G_weighted = nx.read_gml('/kaggle/input/sna-project-files/task2_graph.gml')\n",
    "df = pd.read_parquet('/kaggle/input/sna-project-files/task2_df.parquet')\n",
    "print(f\"Loaded weighted graph: {G_weighted.number_of_nodes()} nodes, {G_weighted.number_of_edges()} edges\")\n",
    "print(f\"Loaded DataFrame: {len(df)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bb3649fc-c767-4f52-9599-ea89b68a2f79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:28.699451Z",
     "iopub.status.busy": "2025-05-05T20:28:28.698880Z",
     "iopub.status.idle": "2025-05-05T20:28:29.075063Z",
     "shell.execute_reply": "2025-05-05T20:28:29.074254Z",
     "shell.execute_reply.started": "2025-05-05T20:28:28.699432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 2972 communities\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Apply Louvain community detection on weighted graph loaded from task 2\n",
    "\n",
    "community_df_weighted= communityLouvainFuc(G, weight=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9f970177-d3cb-476f-bae8-bf75df43be7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:29.076592Z",
     "iopub.status.busy": "2025-05-05T20:28:29.076024Z",
     "iopub.status.idle": "2025-05-05T20:28:29.098899Z",
     "shell.execute_reply": "2025-05-05T20:28:29.098109Z",
     "shell.execute_reply.started": "2025-05-05T20:28:29.076571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Weighted Communities by Size:\n",
      "community_weighted\n",
      "26     156\n",
      "201    102\n",
      "2       98\n",
      "44      97\n",
      "217     60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Shared Features of Top 3 Communities:\n",
      "\n",
      "Community 26 (156 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 113), ('Helsinki', 4), ('Dresden', 4), ('Dinslaken', 3), ('Weil am Rhein', 2)]\n",
      "\n",
      "Top 5 cuisines: [('European', 25), ('Fast food', 23), ('British', 23), ('Mediterranean', 18), ('Italian', 16)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 49), ('Vegan Options', 31), ('Gluten Free Options', 23), ('Halal', 5)]\n",
      "\n",
      "Top 5 features: [('Seating', 34), ('Wheelchair Accessible', 24), ('Takeout', 23), ('Reservations', 20), ('Table Service', 17)]\n",
      "\n",
      "Community 201 (102 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 140), ('Frankfurt', 13), ('Dusseldorf', 9), ('Hannover', 5), ('Sheffield', 5)]\n",
      "\n",
      "Top 5 cuisines: [('European', 39), ('Fast food', 37), ('British', 34), ('Cafe', 29), ('Mediterranean', 23)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 80), ('Vegan Options', 48), ('Gluten Free Options', 32), ('Halal', 6)]\n",
      "\n",
      "Top 5 features: [('Seating', 41), ('Wheelchair Accessible', 33), ('Takeout', 28), ('Reservations', 22), ('Table Service', 21)]\n",
      "\n",
      "Community 2 (98 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 199), ('Frankfurt', 13), ('Dusseldorf', 9), ('Pamplona', 6), ('Hannover', 5)]\n",
      "\n",
      "Top 5 cuisines: [('Fast food', 51), ('European', 50), ('Mediterranean', 43), ('Cafe', 39), ('British', 36)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 103), ('Vegan Options', 66), ('Gluten Free Options', 44), ('Halal', 6)]\n",
      "\n",
      "Top 5 features: [('Seating', 65), ('Wheelchair Accessible', 52), ('Takeout', 41), ('Table Service', 38), ('Reservations', 35)]\n",
      "\n",
      "Community 44 (97 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 203), ('Paris', 79), ('Frankfurt', 13), ('Dusseldorf', 9), ('Pamplona', 6)]\n",
      "\n",
      "Top 5 cuisines: [('European', 60), ('Fast food', 58), ('Mediterranean', 48), ('French', 46), ('Cafe', 46)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 123), ('Vegan Options', 71), ('Gluten Free Options', 48), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 90), ('Wheelchair Accessible', 58), ('Reservations', 55), ('Takeout', 53), ('Table Service', 52)]\n",
      "\n",
      "Community 217 (60 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 220), ('Paris', 79), ('Milan', 43), ('Frankfurt', 13), ('Dusseldorf', 9)]\n",
      "\n",
      "Top 5 cuisines: [('European', 66), ('Mediterranean', 65), ('Italian', 65), ('Fast food', 60), ('Cafe', 48)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 145), ('Vegan Options', 80), ('Gluten Free Options', 56), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 102), ('Wheelchair Accessible', 67), ('Reservations', 67), ('Table Service', 64), ('Takeout', 56)]\n",
      "\n",
      "Community 99 (50 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 220), ('Paris', 79), ('Madrid', 50), ('Milan', 43), ('Frankfurt', 13)]\n",
      "\n",
      "Top 5 cuisines: [('Mediterranean', 81), ('European', 75), ('Italian', 70), ('Spanish', 63), ('Fast food', 62)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 155), ('Vegan Options', 87), ('Gluten Free Options', 64), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 111), ('Reservations', 75), ('Table Service', 73), ('Wheelchair Accessible', 69), ('Takeout', 59)]\n",
      "\n",
      "Community 30 (44 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 220), ('Paris', 79), ('Madrid', 50), ('Rome', 44), ('Milan', 43)]\n",
      "\n",
      "Top 5 cuisines: [('Italian', 96), ('Mediterranean', 92), ('European', 75), ('Fast food', 65), ('Spanish', 64)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 168), ('Vegan Options', 93), ('Gluten Free Options', 67), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 118), ('Reservations', 83), ('Table Service', 80), ('Wheelchair Accessible', 73), ('Takeout', 66)]\n",
      "\n",
      "Community 5 (30 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 250), ('Paris', 79), ('Madrid', 50), ('Rome', 44), ('Milan', 43)]\n",
      "\n",
      "Top 5 cuisines: [('Italian', 100), ('Mediterranean', 98), ('European', 81), ('Fast food', 70), ('Spanish', 64)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 181), ('Vegan Options', 101), ('Gluten Free Options', 73), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 125), ('Reservations', 85), ('Table Service', 82), ('Wheelchair Accessible', 77), ('Takeout', 69)]\n",
      "\n",
      "Community 63 (28 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 255), ('Paris', 79), ('Madrid', 50), ('Milan', 44), ('Rome', 44)]\n",
      "\n",
      "Top 5 cuisines: [('Italian', 100), ('Mediterranean', 99), ('European', 85), ('Fast food', 73), ('Spanish', 64)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 185), ('Vegan Options', 101), ('Gluten Free Options', 73), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 128), ('Reservations', 87), ('Table Service', 84), ('Wheelchair Accessible', 78), ('Takeout', 72)]\n",
      "\n",
      "Community 89 (26 restaurants):\n",
      "\n",
      "Top 5 cities: [('Unknown', 255), ('Paris', 79), ('Madrid', 50), ('Milan', 44), ('Rome', 44)]\n",
      "\n",
      "Top 5 cuisines: [('Mediterranean', 100), ('Italian', 100), ('European', 94), ('Fast food', 73), ('Spanish', 65)]\n",
      "\n",
      "Top 5 special_diets: [('Vegetarian Friendly', 187), ('Vegan Options', 103), ('Gluten Free Options', 73), ('Halal', 6), ('Kosher', 1)]\n",
      "\n",
      "Top 5 features: [('Seating', 132), ('Reservations', 92), ('Table Service', 88), ('Wheelchair Accessible', 78), ('Takeout', 76)]\n"
     ]
    }
   ],
   "source": [
    "community_sizes_weighted = community_df_weighted['community_weighted'].value_counts()\n",
    "print(\"\\nTop 5 Weighted Communities by Size:\")\n",
    "print(community_sizes_weighted.head())\n",
    "\n",
    "\n",
    "# Analyze shared features for top 3 communities\n",
    "cuisines=[]\n",
    "cities=[]\n",
    "special_diets=[]\n",
    "features=[]\n",
    "\n",
    "\n",
    "top_communities = community_sizes_weighted.head(10).index\n",
    "print(\"\\nShared Features of Top 3 Communities:\")\n",
    "\n",
    "for comm in top_communities:\n",
    "    comm_df = community_df_weighted[community_df_weighted['community_weighted'] == comm]\n",
    "    print(f\"\\nCommunity {comm} ({len(comm_df)} restaurants):\")\n",
    "\n",
    "    cities += extract_cuisine_items(comm_df['city'])\n",
    "    print(f\"\\nTop 5 cities: {Counter(cities).most_common(5)}\")\n",
    "    \n",
    "    cuisines += extract_cuisine_items(comm_df['cuisines'])\n",
    "    \n",
    "    print(f\"\\nTop 5 cuisines: {Counter(cuisines).most_common(5)}\")\n",
    "    \n",
    "    special_diets += extract_cuisine_items(comm_df['special_diets'])\n",
    "    print(f\"\\nTop 5 special_diets: {Counter(special_diets).most_common(5)}\")\n",
    "\n",
    "    features += extract_cuisine_items(comm_df['features'])\n",
    "    print(f\"\\nTop 5 features: {Counter(features).most_common(5)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16f320-e82f-462f-ad25-88ab9a3d510d",
   "metadata": {},
   "source": [
    "### Comparision between weighted and unweighted graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e933ecf0-cbd3-4701-87bd-357882478690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:29.101370Z",
     "iopub.status.busy": "2025-05-05T20:28:29.100843Z",
     "iopub.status.idle": "2025-05-05T20:28:29.144720Z",
     "shell.execute_reply": "2025-05-05T20:28:29.144102Z",
     "shell.execute_reply.started": "2025-05-05T20:28:29.101348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Community Structures:\n",
      "Unweighted (Task 6): 2972 communities\n",
      "Weighted (Task 7): 2972 communities\n",
      "\n",
      "Top 5 Unweighted Community Sizes:\n",
      "community_unweighted\n",
      "26     156\n",
      "201    102\n",
      "2       98\n",
      "44      97\n",
      "217     60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 5 Weighted Community Sizes:\n",
      "community_weighted\n",
      "26     156\n",
      "201    102\n",
      "2       98\n",
      "44      97\n",
      "217     60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Adjusted Rand Index (ARI): 1.0000\n",
      "(ARI close to 1: similar partitions; close to 0: dissimilar)\n",
      "\n",
      "=== Shared Features Comparison (Top 3 Communities) ===\n",
      "\n",
      "--- Unweighted Top 5 Communities ---\n",
      "\n",
      "Community 26 (156 restaurants):\n",
      "  Top Cities: [('Unknown', 113), ('Helsinki', 4), ('Dresden', 4), ('Dinslaken', 3), ('Weil am Rhein', 2), ('Llanelli', 2), ('Backnang', 2), ('Wuppertal', 2), ('Delmenhorst', 2), ('Nuremberg', 2)]\n",
      "  Top Cuisines: [('European', 25), ('Fast food', 23), ('British', 23), ('Mediterranean', 18), ('Italian', 16), ('Cafe', 13), ('Pub', 10), ('American', 9), ('Asian', 9), ('Middle Eastern', 8)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 49), ('Vegan Options', 31), ('Gluten Free Options', 23), ('Halal', 5)]\n",
      "  Top Features: [('Seating', 34), ('Wheelchair Accessible', 24), ('Takeout', 23), ('Reservations', 20), ('Table Service', 17), ('Serves Alcohol', 13), ('Highchairs Available', 11), ('Free Wifi', 10), ('Full Bar', 8), ('Accepts Credit Cards', 8)]\n",
      "\n",
      "Community 201 (102 restaurants):\n",
      "  Top Cities: [('Unknown', 27), ('Frankfurt', 13), ('Dusseldorf', 9), ('Hannover', 5), ('Sheffield', 5), ('Portsmouth', 4), ('Hinckley', 4), ('Karlsruhe', 4), ('Brighton', 3), ('Chester', 3)]\n",
      "  Top Cuisines: [('Cafe', 16), ('Fast food', 14), ('European', 14), ('British', 11), ('Asian', 10), ('Bar', 8), ('Italian', 7), ('American', 6), ('Pub', 6), ('Pizza', 5)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 31), ('Vegan Options', 17), ('Gluten Free Options', 9), ('Halal', 1)]\n",
      "  Top Features: [('Wheelchair Accessible', 9), ('Seating', 7), ('Takeout', 5), ('Highchairs Available', 4), ('Table Service', 4), ('Serves Alcohol', 3), ('Accepts Credit Cards', 3), ('Street Parking', 2), ('Free Wifi', 2), ('Reservations', 2)]\n",
      "\n",
      "Community 2 (98 restaurants):\n",
      "  Top Cities: [('Unknown', 59), ('Pamplona', 6), ('Cheltenham', 4), ('Stirling', 4), ('Auxerre', 3), ('Alcala De Henares', 3), ('Bochum', 3), ('La Rochelle', 2), ('Cleethorpes', 2), ('Venissieux', 2)]\n",
      "  Top Cuisines: [('Spanish', 27), ('Mediterranean', 20), ('Fast food', 14), ('European', 11), ('Cafe', 10), ('American', 7), ('French', 6), ('Asian', 6), ('Bar', 6), ('Italian', 5)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 23), ('Vegan Options', 18), ('Gluten Free Options', 12)]\n",
      "  Top Features: [('Seating', 24), ('Wheelchair Accessible', 19), ('Table Service', 17), ('Serves Alcohol', 13), ('Reservations', 13), ('Takeout', 13), ('Outdoor Seating', 9), ('Highchairs Available', 7), ('Accepts Credit Cards', 7), ('Free Wifi', 6)]\n",
      "\n",
      "Community 44 (97 restaurants):\n",
      "  Top Cities: [('Paris', 78), ('Unknown', 4), ('Saint-Maur-des-Fosses', 3), ('Neunkirchen', 3), ('Crawley', 2), ('Boldon', 1), ('Toulouse', 1), ('Wickford', 1), ('Manchester', 1), ('Saint Brice Sous Foret', 1)]\n",
      "  Top Cuisines: [('French', 35), ('European', 10), ('Asian', 8), ('Bar', 7), ('Cafe', 7), ('Fast food', 7), ('Japanese', 6), ('American', 5), ('Italian', 5), ('Pizza', 5)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 20), ('Vegan Options', 5), ('Gluten Free Options', 4), ('Kosher', 1)]\n",
      "  Top Features: [('Seating', 25), ('Reservations', 20), ('Table Service', 14), ('Takeout', 12), ('Serves Alcohol', 8), ('Wheelchair Accessible', 6), ('Accepts Credit Cards', 5), ('Full Bar', 4), ('Highchairs Available', 4), ('Accepts American Express', 4)]\n",
      "\n",
      "Community 217 (60 restaurants):\n",
      "  Top Cities: [('Milan', 43), ('Unknown', 17)]\n",
      "  Top Cuisines: [('Italian', 32), ('Mediterranean', 17), ('Seafood', 12), ('Bar', 8), ('Pizza', 7), ('Spanish', 6), ('European', 6), ('Pub', 5), ('Healthy', 4), ('Barbecue', 3)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 22), ('Vegan Options', 9), ('Gluten Free Options', 8)]\n",
      "  Top Features: [('Reservations', 12), ('Seating', 12), ('Table Service', 12), ('Wheelchair Accessible', 9), ('Serves Alcohol', 7), ('Outdoor Seating', 4), ('Full Bar', 4), ('Free Wifi', 4), ('Accepts Credit Cards', 4), ('Wine and Beer', 3)]\n",
      "\n",
      "Community 99 (50 restaurants):\n",
      "  Top Cities: [('Madrid', 50)]\n",
      "  Top Cuisines: [('Spanish', 26), ('Mediterranean', 16), ('European', 9), ('Italian', 5), ('Bar', 4), ('Cafe', 4), ('International', 4), ('Pub', 3), ('Steakhouse', 2), ('Grill', 2)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 10), ('Gluten Free Options', 8), ('Vegan Options', 7)]\n",
      "  Top Features: [('Seating', 9), ('Table Service', 9), ('Reservations', 8), ('Serves Alcohol', 5), ('Takeout', 3), ('Wheelchair Accessible', 2), ('Free Wifi', 2), ('Accepts Credit Cards', 2), ('Wine and Beer', 2), ('Full Bar', 2)]\n",
      "\n",
      "Community 30 (44 restaurants):\n",
      "  Top Cities: [('Rome', 44)]\n",
      "  Top Cuisines: [('Italian', 26), ('Mediterranean', 11), ('Pizza', 10), ('Central-Italian', 8), ('Seafood', 8), ('Romana', 7), ('Lazio', 7), ('Japanese', 4), ('Asian', 4), ('Fast food', 3)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 13), ('Vegan Options', 6), ('Gluten Free Options', 3)]\n",
      "  Top Features: [('Reservations', 8), ('Seating', 7), ('Table Service', 7), ('Takeout', 7), ('Serves Alcohol', 5), ('Wheelchair Accessible', 4), ('Outdoor Seating', 3), ('Television', 2), ('Accepts Credit Cards', 2), ('Delivery', 2)]\n",
      "\n",
      "Community 5 (30 restaurants):\n",
      "  Top Cities: [('Unknown', 30)]\n",
      "  Top Cuisines: [('Mediterranean', 6), ('European', 6), ('Asian', 5), ('German', 5), ('Fast food', 5), ('Italian', 4), ('Middle Eastern', 4), ('Cafe', 4), ('Turkish', 3), ('Street Food', 3)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 13), ('Vegan Options', 8), ('Gluten Free Options', 6)]\n",
      "  Top Features: [('Seating', 7), ('Wheelchair Accessible', 4), ('Takeout', 3), ('Serves Alcohol', 3), ('Reservations', 2), ('Table Service', 2), ('Wine and Beer', 2), ('Full Bar', 1), ('Accepts Credit Cards', 1), ('Live Music', 1)]\n",
      "\n",
      "Community 63 (28 restaurants):\n",
      "  Top Cities: [('Lille', 11), ('Unknown', 5), ('Saint-Malo', 3), ('Enschede', 2), ('Le Chesnay', 1), ('Kingswood', 1), ('The Hague', 1), ('Issy-les-Moulineaux', 1), ('Milan', 1), ('Sutton in Ashfield', 1)]\n",
      "  Top Cuisines: [('Pizza', 8), ('French', 5), ('European', 4), ('Fast food', 3), ('Bar', 3), ('American', 2), ('Seafood', 2), ('Pub', 2), ('Indian', 2), ('Cafe', 2)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 4)]\n",
      "  Top Features: [('Takeout', 3), ('Seating', 3), ('Delivery', 2), ('Reservations', 2), ('Serves Alcohol', 2), ('Table Service', 2), ('Wheelchair Accessible', 1), ('Full Bar', 1)]\n",
      "\n",
      "Community 89 (26 restaurants):\n",
      "  Top Cities: [('Prague', 26)]\n",
      "  Top Cuisines: [('European', 9), ('Czech', 9), ('Cafe', 5), ('Asian', 2), ('Bar', 2), ('Vietnamese', 1), ('Soups', 1), ('Fusion', 1), ('Pizza', 1), ('French', 1)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 2), ('Vegan Options', 2)]\n",
      "  Top Features: [('Reservations', 5), ('Table Service', 4), ('Takeout', 4), ('Seating', 4), ('Serves Alcohol', 4), ('Free Wifi', 4), ('Outdoor Seating', 2), ('Full Bar', 2), ('Wine and Beer', 2), ('Digital Payments', 2)]\n",
      "\n",
      "--- Weighted Top 5 Communities ---\n",
      "\n",
      "Community 26 (156 restaurants):\n",
      "  Top Cities: [('Unknown', 113), ('Helsinki', 4), ('Dresden', 4), ('Dinslaken', 3), ('Weil am Rhein', 2), ('Llanelli', 2), ('Backnang', 2), ('Wuppertal', 2), ('Delmenhorst', 2), ('Nuremberg', 2)]\n",
      "  Top Cuisines: [('European', 25), ('Fast food', 23), ('British', 23), ('Mediterranean', 18), ('Italian', 16), ('Cafe', 13), ('Pub', 10), ('American', 9), ('Asian', 9), ('Middle Eastern', 8)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 49), ('Vegan Options', 31), ('Gluten Free Options', 23), ('Halal', 5)]\n",
      "  Top Features: [('Seating', 34), ('Wheelchair Accessible', 24), ('Takeout', 23), ('Reservations', 20), ('Table Service', 17), ('Serves Alcohol', 13), ('Highchairs Available', 11), ('Free Wifi', 10), ('Full Bar', 8), ('Accepts Credit Cards', 8)]\n",
      "\n",
      "Community 201 (102 restaurants):\n",
      "  Top Cities: [('Unknown', 27), ('Frankfurt', 13), ('Dusseldorf', 9), ('Hannover', 5), ('Sheffield', 5), ('Portsmouth', 4), ('Hinckley', 4), ('Karlsruhe', 4), ('Brighton', 3), ('Chester', 3)]\n",
      "  Top Cuisines: [('Cafe', 16), ('Fast food', 14), ('European', 14), ('British', 11), ('Asian', 10), ('Bar', 8), ('Italian', 7), ('American', 6), ('Pub', 6), ('Pizza', 5)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 31), ('Vegan Options', 17), ('Gluten Free Options', 9), ('Halal', 1)]\n",
      "  Top Features: [('Wheelchair Accessible', 9), ('Seating', 7), ('Takeout', 5), ('Highchairs Available', 4), ('Table Service', 4), ('Serves Alcohol', 3), ('Accepts Credit Cards', 3), ('Street Parking', 2), ('Free Wifi', 2), ('Reservations', 2)]\n",
      "\n",
      "Community 2 (98 restaurants):\n",
      "  Top Cities: [('Unknown', 59), ('Pamplona', 6), ('Cheltenham', 4), ('Stirling', 4), ('Auxerre', 3), ('Alcala De Henares', 3), ('Bochum', 3), ('La Rochelle', 2), ('Cleethorpes', 2), ('Venissieux', 2)]\n",
      "  Top Cuisines: [('Spanish', 27), ('Mediterranean', 20), ('Fast food', 14), ('European', 11), ('Cafe', 10), ('American', 7), ('French', 6), ('Asian', 6), ('Bar', 6), ('Italian', 5)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 23), ('Vegan Options', 18), ('Gluten Free Options', 12)]\n",
      "  Top Features: [('Seating', 24), ('Wheelchair Accessible', 19), ('Table Service', 17), ('Serves Alcohol', 13), ('Reservations', 13), ('Takeout', 13), ('Outdoor Seating', 9), ('Highchairs Available', 7), ('Accepts Credit Cards', 7), ('Free Wifi', 6)]\n",
      "\n",
      "Community 44 (97 restaurants):\n",
      "  Top Cities: [('Paris', 78), ('Unknown', 4), ('Saint-Maur-des-Fosses', 3), ('Neunkirchen', 3), ('Crawley', 2), ('Boldon', 1), ('Toulouse', 1), ('Wickford', 1), ('Manchester', 1), ('Saint Brice Sous Foret', 1)]\n",
      "  Top Cuisines: [('French', 35), ('European', 10), ('Asian', 8), ('Bar', 7), ('Cafe', 7), ('Fast food', 7), ('Japanese', 6), ('American', 5), ('Italian', 5), ('Pizza', 5)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 20), ('Vegan Options', 5), ('Gluten Free Options', 4), ('Kosher', 1)]\n",
      "  Top Features: [('Seating', 25), ('Reservations', 20), ('Table Service', 14), ('Takeout', 12), ('Serves Alcohol', 8), ('Wheelchair Accessible', 6), ('Accepts Credit Cards', 5), ('Full Bar', 4), ('Highchairs Available', 4), ('Accepts American Express', 4)]\n",
      "\n",
      "Community 217 (60 restaurants):\n",
      "  Top Cities: [('Milan', 43), ('Unknown', 17)]\n",
      "  Top Cuisines: [('Italian', 32), ('Mediterranean', 17), ('Seafood', 12), ('Bar', 8), ('Pizza', 7), ('Spanish', 6), ('European', 6), ('Pub', 5), ('Healthy', 4), ('Barbecue', 3)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 22), ('Vegan Options', 9), ('Gluten Free Options', 8)]\n",
      "  Top Features: [('Reservations', 12), ('Seating', 12), ('Table Service', 12), ('Wheelchair Accessible', 9), ('Serves Alcohol', 7), ('Outdoor Seating', 4), ('Full Bar', 4), ('Free Wifi', 4), ('Accepts Credit Cards', 4), ('Wine and Beer', 3)]\n",
      "\n",
      "Community 99 (50 restaurants):\n",
      "  Top Cities: [('Madrid', 50)]\n",
      "  Top Cuisines: [('Spanish', 26), ('Mediterranean', 16), ('European', 9), ('Italian', 5), ('Bar', 4), ('Cafe', 4), ('International', 4), ('Pub', 3), ('Steakhouse', 2), ('Grill', 2)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 10), ('Gluten Free Options', 8), ('Vegan Options', 7)]\n",
      "  Top Features: [('Seating', 9), ('Table Service', 9), ('Reservations', 8), ('Serves Alcohol', 5), ('Takeout', 3), ('Wheelchair Accessible', 2), ('Free Wifi', 2), ('Accepts Credit Cards', 2), ('Wine and Beer', 2), ('Full Bar', 2)]\n",
      "\n",
      "Community 30 (44 restaurants):\n",
      "  Top Cities: [('Rome', 44)]\n",
      "  Top Cuisines: [('Italian', 26), ('Mediterranean', 11), ('Pizza', 10), ('Central-Italian', 8), ('Seafood', 8), ('Romana', 7), ('Lazio', 7), ('Japanese', 4), ('Asian', 4), ('Fast food', 3)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 13), ('Vegan Options', 6), ('Gluten Free Options', 3)]\n",
      "  Top Features: [('Reservations', 8), ('Seating', 7), ('Table Service', 7), ('Takeout', 7), ('Serves Alcohol', 5), ('Wheelchair Accessible', 4), ('Outdoor Seating', 3), ('Television', 2), ('Accepts Credit Cards', 2), ('Delivery', 2)]\n",
      "\n",
      "Community 5 (30 restaurants):\n",
      "  Top Cities: [('Unknown', 30)]\n",
      "  Top Cuisines: [('Mediterranean', 6), ('European', 6), ('Asian', 5), ('German', 5), ('Fast food', 5), ('Italian', 4), ('Middle Eastern', 4), ('Cafe', 4), ('Turkish', 3), ('Street Food', 3)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 13), ('Vegan Options', 8), ('Gluten Free Options', 6)]\n",
      "  Top Features: [('Seating', 7), ('Wheelchair Accessible', 4), ('Takeout', 3), ('Serves Alcohol', 3), ('Reservations', 2), ('Table Service', 2), ('Wine and Beer', 2), ('Full Bar', 1), ('Accepts Credit Cards', 1), ('Live Music', 1)]\n",
      "\n",
      "Community 63 (28 restaurants):\n",
      "  Top Cities: [('Lille', 11), ('Unknown', 5), ('Saint-Malo', 3), ('Enschede', 2), ('Le Chesnay', 1), ('Kingswood', 1), ('The Hague', 1), ('Issy-les-Moulineaux', 1), ('Milan', 1), ('Sutton in Ashfield', 1)]\n",
      "  Top Cuisines: [('Pizza', 8), ('French', 5), ('European', 4), ('Fast food', 3), ('Bar', 3), ('American', 2), ('Seafood', 2), ('Pub', 2), ('Indian', 2), ('Cafe', 2)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 4)]\n",
      "  Top Features: [('Takeout', 3), ('Seating', 3), ('Delivery', 2), ('Reservations', 2), ('Serves Alcohol', 2), ('Table Service', 2), ('Wheelchair Accessible', 1), ('Full Bar', 1)]\n",
      "\n",
      "Community 89 (26 restaurants):\n",
      "  Top Cities: [('Prague', 26)]\n",
      "  Top Cuisines: [('European', 9), ('Czech', 9), ('Cafe', 5), ('Asian', 2), ('Bar', 2), ('Vietnamese', 1), ('Soups', 1), ('Fusion', 1), ('Pizza', 1), ('French', 1)]\n",
      "  Top Special Diets: [('Vegetarian Friendly', 2), ('Vegan Options', 2)]\n",
      "  Top Features: [('Reservations', 5), ('Table Service', 4), ('Takeout', 4), ('Seating', 4), ('Serves Alcohol', 4), ('Free Wifi', 4), ('Outdoor Seating', 2), ('Full Bar', 2), ('Wine and Beer', 2), ('Digital Payments', 2)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# Step 3: Compare unweighted (Task 6) and weighted (Task 7) communities\n",
    "community_df_unweighted = community_unweighted[['restaurant_name', 'community_unweighted']]\n",
    "community_sizes_unweighted = community_df_unweighted['community_unweighted'].value_counts()\n",
    "print(\"\\nComparison of Community Structures:\")\n",
    "print(f\"Unweighted (Task 6): {len(set(community_df_unweighted['community_unweighted']))} communities\")\n",
    "print(f\"Weighted (Task 7): {len(set(community_df_weighted['community_weighted']))} communities\")\n",
    "\n",
    "print(\"\\nTop 5 Unweighted Community Sizes:\")\n",
    "print(community_sizes_unweighted.head())\n",
    "print(\"\\nTop 5 Weighted Community Sizes:\")\n",
    "print(community_sizes_weighted.head())\n",
    "\n",
    "comparison_df = community_unweighted.merge(\n",
    "    community_df_weighted[['restaurant_name', 'community_weighted']],\n",
    "    on='restaurant_name',\n",
    "    how='inner'\n",
    ")\n",
    "ari = adjusted_rand_score(community_unweighted['community_unweighted'], community_df_weighted['community_weighted'])\n",
    "print(f\"\\nAdjusted Rand Index (ARI): {ari:.4f}\")\n",
    "print(\"(ARI close to 1: similar partitions; close to 0: dissimilar)\")\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "comparison_cities = []\n",
    "comparison_cuisines = []\n",
    "\n",
    "def extract_cuisine_items(column):\n",
    "    all_cuisines = []\n",
    "    for item in column:\n",
    "        if isinstance(item, str) and item.strip() != '[]':\n",
    "            all_cuisines.extend([c.strip() for c in item.split(',')])\n",
    "    return all_cuisines\n",
    "\n",
    "\n",
    "top_communities_unweighted = community_sizes_unweighted.head(10).index\n",
    "top_communities_weighted = community_sizes_weighted.head(10).index\n",
    "\n",
    "\n",
    "# Helper function to compute Jaccard similarity for sets (e.g., cuisines)\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "# Compare shared features of top 3 communities\n",
    "print(\"\\n=== Shared Features Comparison (Top 3 Communities) ===\")\n",
    "for comm_type, comm_df, top_comms, prefix in [\n",
    "    ('Unweighted', community_unweighted, top_communities_unweighted, 'community_unweighted'),\n",
    "    ('Weighted', community_df_weighted, top_communities_weighted, 'community_weighted')\n",
    "]:\n",
    "    print(f\"\\n--- {comm_type} Top 5 Communities ---\")\n",
    "    for comm in top_comms:\n",
    "        comm_data = comm_df[comm_df[prefix] == comm]\n",
    "        print(f\"\\nCommunity {comm} ({len(comm_data)} restaurants):\")\n",
    "        cities = Counter(comm_data['city'].dropna())\n",
    "        print(f\"  Top Cities: {cities.most_common(10)}\")\n",
    "        cuisines = extract_cuisine_items(comm_data['cuisines'])\n",
    "        cuisine_counts = Counter(cuisines)\n",
    "        print(f\"  Top Cuisines: {cuisine_counts.most_common(10)}\")\n",
    "        # print(f\"  Top Cuisines: {cuisines.most_common(5)}\")\n",
    "        \n",
    "        # special_diets = Counter([sd for sublist in comm_data['special_diets'].dropna() for sd in sublist])\n",
    "        special_diets = extract_cuisine_items(comm_data['special_diets'])\n",
    "        special_diets_counts = Counter(special_diets)\n",
    "        print(f\"  Top Special Diets: {special_diets_counts.most_common(10)}\")\n",
    "        # features = Counter([f for sublist in comm_data['features'].dropna() for f in sublist])\n",
    "        features = extract_cuisine_items(comm_data['features'])\n",
    "        features_counts = Counter(features)\n",
    "        print(f\"  Top Features: {features_counts.most_common(10)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5467063b-eed8-41e1-bcd1-6bd3353a7227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:29.145738Z",
     "iopub.status.busy": "2025-05-05T20:28:29.145525Z",
     "iopub.status.idle": "2025-05-05T20:28:29.153676Z",
     "shell.execute_reply": "2025-05-05T20:28:29.152849Z",
     "shell.execute_reply.started": "2025-05-05T20:28:29.145722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cuisine Overlap (Jaccard Similarity) ===\n",
      "\n",
      "\n",
      "Top Community 1 (Unweighted 26 vs. Weighted 26): Jaccard Similarity = 1.0000\n"
     ]
    }
   ],
   "source": [
    "def extract_cuisine_set(series):\n",
    "    cuisines = set()\n",
    "    for item in series.dropna():\n",
    "        if isinstance(item, str):\n",
    "            cuisines.update([c.strip() for c in item.split(',')])\n",
    "        elif isinstance(item, list):\n",
    "            cuisines.update(item)\n",
    "    return cuisines\n",
    "\n",
    "\n",
    "# Compare cuisine overlap between top communities\n",
    "print(\"\\n=== Cuisine Overlap (Jaccard Similarity) ===\\n\\n\")\n",
    "\n",
    "for i, (comm_unw, comm_w) in enumerate(zip(top_communities[:1], top_communities_weighted[:1])):\n",
    "    unw_data = community_unweighted[community_unweighted['community_unweighted'] == comm_unw]\n",
    "    w_data = community_df_weighted[community_df_weighted['community_weighted'] == comm_w]\n",
    "    # print(\"Unweighted Data Columns:\", unw_data.columns.tolist())\n",
    "    # print(\"Weighted Data Columns:\", w_data.columns.tolist())\n",
    "    # print(\"Unweighted Data Columns: Cuisines -> \", w_data['cuisines'].head())\n",
    "    # print(\"Weighted Data Columns: Cuisines -> \", w_data['cuisines'].head())\n",
    "\n",
    "    # unw_cuisines = set(c for sublist in unw_data['cuisines'].dropna())\n",
    "    # w_cuisines = set(c for sublist in w_data['cuisines'].dropna() for c in sublist)\n",
    "    unw_cuisines = extract_cuisine_set(unw_data['cuisines'])\n",
    "    w_cuisines = extract_cuisine_set(w_data['cuisines'])\n",
    "    jaccard = jaccard_similarity(unw_cuisines, w_cuisines)\n",
    "    print(f\"Top Community {i+1} (Unweighted {comm_unw} vs. Weighted {comm_w}): Jaccard Similarity = {jaccard:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a94844d0-4947-4bbc-b05e-5f197b850cf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:29.154695Z",
     "iopub.status.busy": "2025-05-05T20:28:29.154485Z",
     "iopub.status.idle": "2025-05-05T20:28:29.171127Z",
     "shell.execute_reply": "2025-05-05T20:28:29.170408Z",
     "shell.execute_reply.started": "2025-05-05T20:28:29.154681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/task7_community_weighted_graph.html\n",
      "Community visualization saved to /kaggle/working/task7_community_weighted_graph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"task7_community_weighted_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x797e531cb250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Add nodes with colors and titles\n",
    "colors = ['#FF9999', '#66CC99', '#99CCFF', '#FFCC99', '#CC99FF']\n",
    "for node in G_top.nodes():\n",
    "    comm = partition[node]\n",
    "    city = community_df_weighted[community_df_weighted['restaurant_name'] == node]['city'].iloc[0]\n",
    "    net.add_node(node, label=node, title=f\"{node}\\nCommunity: {comm}\\nCity: {city}\", color=colors[comm % len(colors)])\n",
    "\n",
    "# Add edges with color\n",
    "for source, target in G_top.edges():\n",
    "    net.add_edge(source, target, color='#888888')\n",
    "\n",
    "\n",
    "\n",
    "net.show_buttons(filter_=['physics'])\n",
    "net.show(\"/kaggle/working/task7_community_weighted_graph.html\")\n",
    "print(\"Community visualization saved to /kaggle/working/task7_community_weighted_graph.html\")\n",
    "\n",
    "# net.show(\"/kaggle/working/task6_community_graph.html\")  # This creates the file\n",
    "# display(IFrame(\"task7_community_graph.html\", width=\"100%\", height=\"600px\"))\n",
    "showMyHtmlGraph('task7_community_weighted_graph.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d076c77e-c99f-47b9-926c-31ef85eadca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:29.172127Z",
     "iopub.status.busy": "2025-05-05T20:28:29.171875Z",
     "iopub.status.idle": "2025-05-05T20:28:29.319626Z",
     "shell.execute_reply": "2025-05-05T20:28:29.319102Z",
     "shell.execute_reply.started": "2025-05-05T20:28:29.172112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved community assignments to /kaggle/working/task7_communities.csv and unweighted graph to /kaggle/working/task7_weighted_graph.gml\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Save results\n",
    "community_df_weighted.to_csv('/kaggle/working/task7_communities.csv', index=False)\n",
    "nx.write_gml(G, '/kaggle/working/task7_weighted_graph.gml')\n",
    "print(\"Saved community assignments to /kaggle/working/task7_communities.csv and unweighted graph to /kaggle/working/task7_weighted_graph.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f05652-972d-4167-90af-8df871c96b5a",
   "metadata": {},
   "source": [
    "### 8. Role of Dietary Preferences\n",
    "\n",
    "- Filter nodes with vegetarian_friendly, vegan_options, or gluten_free tags.\n",
    "- Analyze their position in the network (e.g., density, centrality, community inclusion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "04a610bf-b7ae-4e9f-a240-406dd4f1afc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:29.320506Z",
     "iopub.status.busy": "2025-05-05T20:28:29.320265Z",
     "iopub.status.idle": "2025-05-05T20:28:30.269382Z",
     "shell.execute_reply": "2025-05-05T20:28:30.268576Z",
     "shell.execute_reply.started": "2025-05-05T20:28:29.320486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weighted graph: 4846 nodes, 11238 edges\n",
      "Loaded DataFrame: 5000 rows\n",
      "Loaded Task 7 communities: 5000 restaurants\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Task 2 weighted graph, DataFrame, and Task 7 communities\n",
    "G = nx.read_gml('/kaggle/input/sna-project-files/task2_graph.gml')\n",
    "df = pd.read_parquet('/kaggle/input/sna-project-files/task2_df.parquet')\n",
    "community_df_weighted = pd.read_csv('/kaggle/working/task7_communities.csv')\n",
    "print(f\"Loaded weighted graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "print(f\"Loaded DataFrame: {len(df)} rows\")\n",
    "print(f\"Loaded Task 7 communities: {len(community_df_weighted)} restaurants\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af8c6d-a1f5-40b1-9034-fcdffb770dd3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Step 1: Filter nodes with vegetarian_friendly, vegan_options, or gluten_free tags\n",
    "### Parse special_diets column (stringified lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c633b73e-2444-471a-b4c0-eea1ad4b6cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:47.144891Z",
     "iopub.status.busy": "2025-05-05T20:28:47.144617Z",
     "iopub.status.idle": "2025-05-05T20:28:47.156360Z",
     "shell.execute_reply": "2025-05-05T20:28:47.155561Z",
     "shell.execute_reply.started": "2025-05-05T20:28:47.144870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['restaurant_link', 'restaurant_name', 'original_location', 'country', 'region', 'province', 'city', 'address', 'latitude', 'longitude', 'claimed', 'awards', 'popularity_detailed', 'popularity_generic', 'top_tags', 'price_level', 'price_range', 'meals', 'cuisines', 'special_diets', 'features', 'vegetarian_friendly', 'vegan_options', 'gluten_free', 'original_open_hours', 'open_days_per_week', 'open_hours_per_week', 'working_shifts_per_week', 'avg_rating', 'total_reviews_count', 'default_language', 'reviews_count_in_default_language', 'excellent', 'very_good', 'average', 'poor', 'terrible', 'food', 'service', 'value', 'atmosphere', 'keywords']\n",
      "\n",
      "\n",
      "====== \n",
      "\n",
      " Found  1585 restaurants with dietary tags\n",
      "\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.columns.tolist())\n",
    "\n",
    " # Define dietary tags\n",
    "\n",
    "dietary_tags = ['vegetarian_friendly', 'vegan_options', 'gluten_free']\n",
    "dietary_nodes = []\n",
    "\n",
    "# Loop through each dietary tag column\n",
    "for tag in dietary_tags:\n",
    "    if tag in df.columns:\n",
    "        matches = df[df[tag] == 'Y']['restaurant_name'].tolist()\n",
    "        dietary_nodes.extend(matches)\n",
    "\n",
    "# Remove duplicates\n",
    "dietary_nodes = list(set(dietary_nodes))\n",
    "print(f\"\\n\\n====== \\n\\n Found  {len(dietary_nodes)} restaurants with dietary tags\\n\\n======\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a7fcad22-cd1e-4362-a349-a3a8c68b8d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:48.066627Z",
     "iopub.status.busy": "2025-05-05T20:28:48.066377Z",
     "iopub.status.idle": "2025-05-05T20:28:54.646827Z",
     "shell.execute_reply": "2025-05-05T20:28:54.646096Z",
     "shell.execute_reply.started": "2025-05-05T20:28:48.066608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dietary subgraph: 1585 nodes, 1251 edges\n",
      "\n",
      "Density Analysis:\n",
      "Dietary subgraph density: 0.000997\n",
      "Full graph density: 0.000957\n",
      "(Higher density means more connections among dietary restaurants)\n",
      "\n",
      "Centrality Analysis:\n",
      "Average degree centrality (dietary): 0.000972\n",
      "Average degree centrality (all): 0.000957\n",
      "Average betweenness centrality (dietary): 0.000013\n",
      "Average betweenness centrality (all): 0.000011\n",
      "(Higher centrality means dietary restaurants are more connected or influential)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Analyze network position\n",
    "# Create subgraph of dietary nodes\n",
    "\n",
    "G_dietary = G.subgraph(dietary_nodes)\n",
    "print(f\"Dietary subgraph: {G_dietary.number_of_nodes()} nodes, {G_dietary.number_of_edges()} edges\")\n",
    "\n",
    "# Density of dietary subgraph\n",
    "density = nx.density(G_dietary)\n",
    "\n",
    "full_graph_density = nx.density(G)\n",
    "print(f\"\\nDensity Analysis:\")\n",
    "print(f\"Dietary subgraph density: {density:.6f}\")\n",
    "print(f\"Full graph density: {full_graph_density:.6f}\")\n",
    "print(\"(Higher density means more connections among dietary restaurants)\")\n",
    "\n",
    "# Centrality in the full graph\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G, k=min(1000, G.number_of_nodes()), weight='weight')\n",
    "\n",
    "# Compute centrality for dietary nodes\n",
    "dietary_centrality = pd.DataFrame({\n",
    "    'restaurant_name': dietary_nodes,\n",
    "    'degree_centrality': [degree_centrality[node] for node in dietary_nodes],\n",
    "    'betweenness_centrality': [betweenness_centrality[node] for node in dietary_nodes]\n",
    "})\n",
    "\n",
    "\n",
    "# Average centrality for dietary vs. all nodes\n",
    "avg_degree_dietary = dietary_centrality['degree_centrality'].mean()\n",
    "avg_degree_all = sum(degree_centrality.values()) / len(degree_centrality)\n",
    "avg_betweenness_dietary = dietary_centrality['betweenness_centrality'].mean()\n",
    "avg_betweenness_all = sum(betweenness_centrality.values()) / len(betweenness_centrality)\n",
    "\n",
    "print(f\"\\nCentrality Analysis:\")\n",
    "print(f\"Average degree centrality (dietary): {avg_degree_dietary:.6f}\")\n",
    "print(f\"Average degree centrality (all): {avg_degree_all:.6f}\")\n",
    "print(f\"Average betweenness centrality (dietary): {avg_betweenness_dietary:.6f}\")\n",
    "print(f\"Average betweenness centrality (all): {avg_betweenness_all:.6f}\")\n",
    "print(\"(Higher centrality means dietary restaurants are more connected or influential)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b5b66199-dfbb-482d-9797-80053bbf20c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:28:54.648397Z",
     "iopub.status.busy": "2025-05-05T20:28:54.648133Z",
     "iopub.status.idle": "2025-05-05T20:28:54.727467Z",
     "shell.execute_reply": "2025-05-05T20:28:54.726646Z",
     "shell.execute_reply.started": "2025-05-05T20:28:54.648376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Dietary Restaurants by Degree Centrality:\n",
      "         restaurant_name  degree_centrality\n",
      "241        Pret a Manger           0.016718\n",
      "1428        Café Etienne           0.015067\n",
      "494        Le Gribouille           0.014861\n",
      "1295            Angelina           0.014654\n",
      "757   Restaurant Sannine           0.014448\n",
      "\n",
      "Top 5 Dietary Restaurants by Betweenness Centrality:\n",
      "           restaurant_name  betweenness_centrality\n",
      "241          Pret a Manger                0.003575\n",
      "1570  Bread Street Kitchen                0.003275\n",
      "503         Domino's Pizza                0.002543\n",
      "1524          Ugarit Sants                0.001853\n",
      "1445         Mudec Bistrot                0.001353\n",
      "\n",
      "Community Inclusion Analysis:\n",
      "Dietary restaurants in Task 7 communities (top 5):\n",
      "community_weighted\n",
      "26     51\n",
      "201    31\n",
      "2      27\n",
      "44     25\n",
      "217    23\n",
      "Name: count, dtype: int64\n",
      "Total communities with dietary restaurants: 1133\n",
      "\n",
      "=== Dietary Tags in Top 10 Communities ===\n",
      "\n",
      "Community 26 (156 total restaurants):\n",
      "  vegetarian_friendly: 49 restaurants with 'vegetarian_friendly' = Y\n",
      "  vegan_options: 31 restaurants with 'vegan_options' = Y\n",
      "  gluten_free: 23 restaurants with 'gluten_free' = Y\n",
      "\n",
      "Community 201 (102 total restaurants):\n",
      "  vegetarian_friendly: 31 restaurants with 'vegetarian_friendly' = Y\n",
      "  vegan_options: 17 restaurants with 'vegan_options' = Y\n",
      "  gluten_free: 9 restaurants with 'gluten_free' = Y\n",
      "\n",
      "Community 2 (98 total restaurants):\n",
      "  vegetarian_friendly: 23 restaurants with 'vegetarian_friendly' = Y\n",
      "  vegan_options: 18 restaurants with 'vegan_options' = Y\n",
      "  gluten_free: 12 restaurants with 'gluten_free' = Y\n",
      "\n",
      "Community 44 (97 total restaurants):\n",
      "  vegetarian_friendly: 20 restaurants with 'vegetarian_friendly' = Y\n",
      "  vegan_options: 5 restaurants with 'vegan_options' = Y\n",
      "  gluten_free: 4 restaurants with 'gluten_free' = Y\n",
      "\n",
      "Community 217 (60 total restaurants):\n",
      "  vegetarian_friendly: 22 restaurants with 'vegetarian_friendly' = Y\n",
      "  vegan_options: 9 restaurants with 'vegan_options' = Y\n",
      "  gluten_free: 8 restaurants with 'gluten_free' = Y\n",
      "\n",
      "Community 99 (50 total restaurants):\n",
      "  vegetarian_friendly: 10 restaurants with 'vegetarian_friendly' = Y\n",
      "  vegan_options: 7 restaurants with 'vegan_options' = Y\n",
      "  gluten_free: 8 restaurants with 'gluten_free' = Y\n",
      "\n",
      "Community 30 (44 total restaurants):\n",
      "  vegetarian_friendly: 13 restaurants with 'vegetarian_friendly' = Y\n",
      "  vegan_options: 6 restaurants with 'vegan_options' = Y\n",
      "  gluten_free: 3 restaurants with 'gluten_free' = Y\n",
      "\n",
      "Community 5 (30 total restaurants):\n",
      "  vegetarian_friendly: 13 restaurants with 'vegetarian_friendly' = Y\n",
      "  vegan_options: 8 restaurants with 'vegan_options' = Y\n",
      "  gluten_free: 6 restaurants with 'gluten_free' = Y\n",
      "\n",
      "Community 63 (28 total restaurants):\n",
      "  vegetarian_friendly: 4 restaurants with 'vegetarian_friendly' = Y\n",
      "  vegan_options: 0 restaurants with 'vegan_options' = Y\n",
      "  gluten_free: 0 restaurants with 'gluten_free' = Y\n",
      "\n",
      "Community 89 (26 total restaurants):\n",
      "  vegetarian_friendly: 2 restaurants with 'vegetarian_friendly' = Y\n",
      "  vegan_options: 2 restaurants with 'vegan_options' = Y\n",
      "  gluten_free: 0 restaurants with 'gluten_free' = Y\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Top 5 dietary nodes by centrality\n",
    "print(f\"\\nTop 5 Dietary Restaurants by Degree Centrality:\")\n",
    "print(dietary_centrality.sort_values('degree_centrality', ascending=False)[['restaurant_name', 'degree_centrality']].head())\n",
    "print(f\"\\nTop 5 Dietary Restaurants by Betweenness Centrality:\")\n",
    "print(dietary_centrality.sort_values('betweenness_centrality', ascending=False)[['restaurant_name', 'betweenness_centrality']].head())\n",
    "\n",
    "# Community inclusion (using Task 7 weighted communities)\n",
    "dietary_communities = community_df_weighted[community_df_weighted['restaurant_name'].isin(dietary_nodes)]\n",
    "community_distribution = dietary_communities['community_weighted'].value_counts()\n",
    "print(f\"\\nCommunity Inclusion Analysis:\")\n",
    "print(f\"Dietary restaurants in Task 7 communities (top 5):\")\n",
    "print(community_distribution.head())\n",
    "print(f\"Total communities with dietary restaurants: {len(community_distribution)}\")\n",
    "\n",
    "# Analyze dietary tags per community\n",
    "\n",
    "\n",
    "# from collections import Counter\n",
    "\n",
    "# Define dietary tags\n",
    "# dietary_tags = ['vegetarian_friendly', 'vegan_options', 'gluten_free']\n",
    "\n",
    "print(\"\\n=== Dietary Tags in Top 10 Communities ===\")\n",
    "top_communities = community_df_weighted['community_weighted'].value_counts().head(10).index\n",
    "\n",
    "for comm in top_communities:\n",
    "    # Filter the community\n",
    "    comm_df = community_df_weighted[community_df_weighted['community_weighted'] == comm]\n",
    "    \n",
    "    # Find all restaurant names in this community\n",
    "    comm_nodes = comm_df['restaurant_name'].tolist()\n",
    "    \n",
    "    # Initialize tag counter\n",
    "    tag_counter = Counter()\n",
    "    \n",
    "    # For each tag, check which restaurants in this community have 'Y'\n",
    "    for tag in dietary_tags:\n",
    "        # Get restaurant names where the tag is 'Y'\n",
    "        y_nodes = df[df[tag] == 'Y']['restaurant_name']\n",
    "        \n",
    "        # Count how many of those nodes are in the current community\n",
    "        count = sum(name in comm_nodes for name in y_nodes)\n",
    "        tag_counter[tag] = count\n",
    "\n",
    "    print(f\"\\nCommunity {comm} ({len(comm_df)} total restaurants):\")\n",
    "    for tag, count in tag_counter.items():\n",
    "        print(f\"  {tag}: {count} restaurants with '{tag}' = Y\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2b177851-e41d-4787-b9d0-cb270f95aff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:30:18.683884Z",
     "iopub.status.busy": "2025-05-05T20:30:18.683112Z",
     "iopub.status.idle": "2025-05-05T20:30:20.988367Z",
     "shell.execute_reply": "2025-05-05T20:30:20.987673Z",
     "shell.execute_reply.started": "2025-05-05T20:30:18.683856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization subgraph: 1585 nodes, 1251 edges\n",
      "/kaggle/working/task8_dietary_graph.html\n",
      "Visualization saved to /kaggle/working/task8_dietary_graph.html\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Visualize dietary nodes\n",
    "def visualize_dietary_nodes(graph, nodes, df, community_df, output_file):\n",
    "    \"\"\"Visualize a sample of dietary nodes with PyVis.\"\"\"\n",
    "   \n",
    "    G_sample = graph.subgraph(nodes)\n",
    "    print(f\"Visualization subgraph: {G_sample.number_of_nodes()} nodes, {G_sample.number_of_edges()} edges\")\n",
    "    \n",
    "    net = Network(notebook=True, height=\"600px\", width=\"100%\", directed=False, cdn_resources='in_line')\n",
    "    \n",
    "    colors = {\n",
    "        'vegetarian_friendly': '#66CC99',\n",
    "        'vegan_options': '#FF9999',\n",
    "        'gluten_free': '#99CCFF',\n",
    "        'multiple': '#CC99FF',\n",
    "        'unknown': '#888888'\n",
    "    }\n",
    "    \n",
    "    # Set node properties\n",
    "    for node in G_sample.nodes():\n",
    "        node_row = df[df['restaurant_name'] == node]\n",
    "        if not node_row.empty:\n",
    "            node_tags = [tag for tag in node_row['special_diets'].iloc[0] if tag in colors]\n",
    "            color = colors['multiple'] if len(node_tags) > 1 else colors.get(node_tags[0] if node_tags else 'unknown')\n",
    "        else:\n",
    "            node_tags = ['unknown']\n",
    "            color = colors['unknown']\n",
    "        \n",
    "        comm_row = community_df[community_df['restaurant_name'] == node]\n",
    "        comm = comm_row['community_weighted'].iloc[0] if not comm_row.empty else 'unknown'\n",
    "        \n",
    "        net.add_node(\n",
    "            node,\n",
    "            label=node,\n",
    "            color=color,\n",
    "            title=f\"{node}\\nTags: {node_tags}\\nCommunity: {comm}\"\n",
    "        )\n",
    "    \n",
    "    # Set edge properties\n",
    "    for edge in G_sample.edges(data=True):\n",
    "        net.add_edge(\n",
    "            edge[0],\n",
    "            edge[1],\n",
    "            color='#888888',\n",
    "            value=edge[2].get('weight', 1),\n",
    "            title=f\"Weight: {edge[2].get('weight', 1):.2f}\"\n",
    "        )\n",
    "    \n",
    "    net.show_buttons(filter_=['physics'])\n",
    "    net.show(output_file)\n",
    "    print(f\"Visualization saved to {output_file}\")\n",
    "\n",
    "visualize_dietary_nodes(G, dietary_nodes, df, community_df_weighted, \"/kaggle/working/task8_dietary_graph.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "62ecdd59-c7b1-413c-91b3-fc7140a41388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:30:52.718588Z",
     "iopub.status.busy": "2025-05-05T20:30:52.717895Z",
     "iopub.status.idle": "2025-05-05T20:30:52.899353Z",
     "shell.execute_reply": "2025-05-05T20:30:52.898684Z",
     "shell.execute_reply.started": "2025-05-05T20:30:52.718565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing community assignments: 0\n",
      "Saved analysis to /kaggle/working/task8_dietary_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Save results\n",
    "dietary_centrality['community_weighted'] = dietary_centrality['restaurant_name'].map(\n",
    "    community_df_weighted.set_index('restaurant_name')['community_weighted'].get\n",
    ")\n",
    "# Check for missing community assignments\n",
    "missing_communities = dietary_centrality['community_weighted'].isna().sum()\n",
    "print(f\"Missing community assignments: {missing_communities}\")\n",
    "dietary_centrality.to_csv('/kaggle/working/task8_dietary_analysis.csv', index=False)\n",
    "print(\"Saved analysis to /kaggle/working/task8_dietary_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "444fc02a-6399-4e42-8500-4ed9d0f22907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:32:43.588147Z",
     "iopub.status.busy": "2025-05-05T20:32:43.587852Z",
     "iopub.status.idle": "2025-05-05T20:32:43.592948Z",
     "shell.execute_reply": "2025-05-05T20:32:43.592220Z",
     "shell.execute_reply.started": "2025-05-05T20:32:43.588124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"task8_dietary_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x797e606e43d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "showMyHtmlGraph('task8_dietary_graph.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1792b5-15a2-4cf1-b370-abd87a85edad",
   "metadata": {},
   "source": [
    "# task9\n",
    "## Subnetwork Analysis by Region \n",
    "- Extract subnetworks by city or country. \n",
    "- Compare SNA statistics: density, diameter, clustering coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe35ed3-d110-4c12-8edc-905a526dbcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvis in /opt/conda/lib/python3.11/site-packages (0.3.2)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from pyvis) (8.22.2)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /opt/conda/lib/python3.11/site-packages (from pyvis) (3.1.3)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from pyvis) (4.0.5)\n",
      "Requirement already satisfied: networkx>=1.11 in /opt/conda/lib/python3.11/site-packages (from pyvis) (3.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.11/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.11/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/lib/python3.11/site-packages (from seaborn) (3.9.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2>=2.9.6->pyvis) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyvis seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "264a309f-e2be-42e2-97eb-4533bd418b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph: 4846 nodes, 11238 edges\n",
      "Loaded DataFrame: 5000 rows\n",
      "DataFrame columns: ['restaurant_link', 'restaurant_name', 'original_location', 'country', 'region', 'province', 'city', 'address', 'latitude', 'longitude', 'claimed', 'awards', 'popularity_detailed', 'popularity_generic', 'top_tags', 'price_level', 'price_range', 'meals', 'cuisines', 'special_diets', 'features', 'vegetarian_friendly', 'vegan_options', 'gluten_free', 'original_open_hours', 'open_days_per_week', 'open_hours_per_week', 'working_shifts_per_week', 'avg_rating', 'total_reviews_count', 'default_language', 'reviews_count_in_default_language', 'excellent', 'very_good', 'average', 'poor', 'terrible', 'food', 'service', 'value', 'atmosphere', 'keywords']\n",
      "Top 10 cities by restaurant count:\n",
      "city\n",
      "Unknown      1831\n",
      "Paris          79\n",
      "Madrid         53\n",
      "Rome           49\n",
      "Milan          45\n",
      "Prague         29\n",
      "Vienna         23\n",
      "Amsterdam      22\n",
      "Lisbon         21\n",
      "Munich         18\n",
      "Name: count, dtype: int64\n",
      "Subgraph for Unknown: 1807 nodes, 4365 edges\n",
      "Subgraph for Paris: 79 nodes, 2280 edges\n",
      "Subgraph for Madrid: 53 nodes, 797 edges\n",
      "Subgraph for Rome: 49 nodes, 353 edges\n",
      "Subgraph for Milan: 45 nodes, 758 edges\n",
      "Subgraph for Prague: 29 nodes, 196 edges\n",
      "Subgraph for Vienna: 23 nodes, 144 edges\n",
      "Subgraph for Amsterdam: 22 nodes, 212 edges\n",
      "Subgraph for Lisbon: 21 nodes, 178 edges\n",
      "Subgraph for Munich: 18 nodes, 97 edges\n",
      "\n",
      "SNA Statistics for Top Cities:\n",
      "        city  nodes  edges   density  diameter  clustering_coefficient\n",
      "0    Unknown   1807   4365  0.002675        11                0.200534\n",
      "1      Paris     79   2280  0.740019         3                0.447063\n",
      "2     Madrid     53    797  0.578374         6                0.472787\n",
      "3       Rome     49    353  0.300170         6                0.340423\n",
      "4      Milan     45    758  0.765657         3                0.506685\n",
      "5     Prague     29    196  0.482759         4                0.517521\n",
      "6     Vienna     23    144  0.569170         3                0.427037\n",
      "7  Amsterdam     22    212  0.917749         2                0.532416\n",
      "8     Lisbon     21    178  0.847619         2                0.545909\n",
      "9     Munich     18     97  0.633987         2                0.378110\n",
      "Saved SNA comparison plot to /task9_sna_comparison.png\n",
      "Visualization subgraph for Unknown: 300 nodes, 112 edges\n",
      "./task9_Unknown_graph.html\n",
      "Visualization saved to ./task9_Unknown_graph.html\n",
      "Saved SNA statistics to ./task9_sna_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Load Task 2 graph and DataFrame\n",
    "G = nx.read_gml('./task2_graph.gml')\n",
    "df = pd.read_parquet('./task2_df.parquet')\n",
    "print(f\"Loaded graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "print(f\"Loaded DataFrame: {len(df)} rows\")\n",
    "\n",
    "# Step 1: Extract subnetworks by city\n",
    "# Check available columns\n",
    "print(\"DataFrame columns:\", df.columns.tolist())\n",
    "\n",
    "# Verify city column exists\n",
    "if 'city' not in df.columns:\n",
    "    raise KeyError(\"Column 'city' not found in task2_df.parquet. Please check the DataFrame.\")\n",
    "\n",
    "# Get top 10 cities by restaurant count\n",
    "city_counts = df['city'].value_counts()\n",
    "top_cities = city_counts.head(10).index.tolist()\n",
    "print(f\"Top 10 cities by restaurant count:\\n{city_counts.head(10)}\")\n",
    "\n",
    "# Create subnetworks for top cities\n",
    "subgraphs = {}\n",
    "for city in top_cities:\n",
    "    # Get restaurant names in this city\n",
    "    city_nodes = df[df['city'] == city]['restaurant_name'].tolist()\n",
    "    # Filter nodes that exist in the graph\n",
    "    city_nodes = [node for node in city_nodes if node in G.nodes()]\n",
    "    # Create subgraph\n",
    "    subgraph = G.subgraph(city_nodes)\n",
    "    subgraphs[city] = subgraph\n",
    "    print(f\"Subgraph for {city}: {subgraph.number_of_nodes()} nodes, {subgraph.number_of_edges()} edges\")\n",
    "\n",
    "# Step 2: Compute SNA statistics\n",
    "sna_stats = []\n",
    "for city, subgraph in subgraphs.items():\n",
    "    if subgraph.number_of_nodes() == 0:\n",
    "        continue\n",
    "    # Density\n",
    "    density = nx.density(subgraph) if subgraph.number_of_nodes() > 1 else 0\n",
    "    # Diameter (use largest connected component)\n",
    "    try:\n",
    "        components = list(nx.connected_components(subgraph))\n",
    "        if components:\n",
    "            largest_cc = max(components, key=len)\n",
    "            subgraph_cc = subgraph.subgraph(largest_cc)\n",
    "            diameter = nx.diameter(subgraph_cc) if subgraph_cc.number_of_nodes() > 1 else 0\n",
    "        else:\n",
    "            diameter = 0\n",
    "    except:\n",
    "        diameter = 0\n",
    "    # Clustering coefficient (weighted)\n",
    "    clustering = nx.average_clustering(subgraph, weight='weight') if subgraph.number_of_nodes() > 1 else 0\n",
    "    sna_stats.append({\n",
    "        'city': city,\n",
    "        'nodes': subgraph.number_of_nodes(),\n",
    "        'edges': subgraph.number_of_edges(),\n",
    "        'density': density,\n",
    "        'diameter': diameter,\n",
    "        'clustering_coefficient': clustering\n",
    "    })\n",
    "\n",
    "# Create DataFrame for SNA stats\n",
    "sna_df = pd.DataFrame(sna_stats)\n",
    "print(\"\\nSNA Statistics for Top Cities:\")\n",
    "print(sna_df)\n",
    "\n",
    "# Step 3: Compare SNA statistics\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=sna_df.melt(id_vars=['city'], value_vars=['density', 'diameter', 'clustering_coefficient']),\n",
    "            x='city', y='value', hue='variable')\n",
    "plt.title('SNA Statistics Comparison Across Top Cities')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Value')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./task9_sna_comparison.png')\n",
    "plt.close()\n",
    "print(\"Saved SNA comparison plot to /task9_sna_comparison.png\")\n",
    "\n",
    "# Step 4: Visualize one city's subnetwork (e.g., top city)\n",
    "def visualize_subnetwork(graph, city, df, output_file, sample_size=300):\n",
    "    \"\"\"Visualize a city's subnetwork with PyVis.\"\"\"\n",
    "    sample_nodes = list(graph.nodes())[:min(sample_size, graph.number_of_nodes())]\n",
    "    G_sample = graph.subgraph(sample_nodes)\n",
    "    print(f\"Visualization subgraph for {city}: {G_sample.number_of_nodes()} nodes, {G_sample.number_of_edges()} edges\")\n",
    "    \n",
    "    net = Network(notebook=True, height=\"600px\", width=\"100%\", directed=False, cdn_resources='in_line')\n",
    "    \n",
    "    # Set node properties\n",
    "    for node in G_sample.nodes():\n",
    "        node_row = df[df['restaurant_name'] == node]\n",
    "        color = '#66CC99' if not node_row.empty else '#888888'\n",
    "        net.add_node(\n",
    "            node,\n",
    "            label=node,\n",
    "            color=color,\n",
    "            title=f\"{node}\\nCity: {city}\"\n",
    "        )\n",
    "    \n",
    "    # Set edge properties\n",
    "    for edge in G_sample.edges(data=True):\n",
    "        net.add_edge(\n",
    "            edge[0],\n",
    "            edge[1],\n",
    "            color='#888888',\n",
    "            value=edge[2].get('weight', 1),\n",
    "            title=f\"Weight: {edge[2].get('weight', 1):.2f}\"\n",
    "        )\n",
    "    \n",
    "    net.show_buttons(filter_=['physics'])\n",
    "    net.show(output_file)\n",
    "    print(f\"Visualization saved to {output_file}\")\n",
    "\n",
    "# Visualize the top city\n",
    "top_city = top_cities[0]\n",
    "visualize_subnetwork(subgraphs[top_city], top_city, df, f\"./task9_{top_city}_graph.html\")\n",
    "\n",
    "# Step 5: Save SNA stats\n",
    "sna_df.to_csv('./task9_sna_stats.csv', index=False)\n",
    "print(\"Saved SNA statistics to ./task9_sna_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde944a-46cd-4e81-bf9c-08fe4e179a7d",
   "metadata": {},
   "source": [
    "# task 10\n",
    "## Visualization of the Global Network \n",
    "- Visualize the full network with: \n",
    "- Node color = community \n",
    "- Node size = total reviews or rating \n",
    "- Edge width = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bee847a-949b-499b-a5c2-57431781e17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph: 4846 nodes, 11238 edges\n",
      "Loaded DataFrame: 5000 rows\n",
      "Loaded communities: 5000 restaurants\n",
      "DataFrame columns: ['restaurant_link', 'restaurant_name', 'original_location', 'country', 'region', 'province', 'city', 'address', 'latitude', 'longitude', 'claimed', 'awards', 'popularity_detailed', 'popularity_generic', 'top_tags', 'price_level', 'price_range', 'meals', 'cuisines', 'special_diets', 'features', 'vegetarian_friendly', 'vegan_options', 'gluten_free', 'original_open_hours', 'open_days_per_week', 'open_hours_per_week', 'working_shifts_per_week', 'avg_rating', 'total_reviews_count', 'default_language', 'reviews_count_in_default_language', 'excellent', 'very_good', 'average', 'poor', 'terrible', 'food', 'service', 'value', 'atmosphere', 'keywords']\n",
      "Community DataFrame columns: ['restaurant_name', 'community_weighted', 'city', 'cuisines', 'special_diets', 'features', 'latitude', 'longitude']\n",
      "Warning: 'total_reviews' not found. Using uniform node sizes.\n",
      "Merged DataFrame: 7098 rows\n",
      "Sampled 1000 nodes for visualization\n",
      "Sampled subgraph: 711 nodes, 685 edges\n",
      "Number of unique communities: 2972\n",
      "./task10_global_network.html\n",
      "Visualization saved to ./task10_global_network.html\n",
      "Saved sampled nodes to ./task10_sampled_nodes.csv\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.colors as mcolors# Load Task 2 graph and DataFrame, and Task 7 communities\n",
    "G = nx.read_gml('./task2_graph.gml')\n",
    "df = pd.read_parquet('./task2_df.parquet')\n",
    "community_df = pd.read_csv('./task7_communities.csv')\n",
    "print(f\"Loaded graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "print(f\"Loaded DataFrame: {len(df)} rows\")\n",
    "print(f\"Loaded communities: {len(community_df)} restaurants\")\n",
    "\n",
    "# Verify required columns\n",
    "print(\"DataFrame columns:\", df.columns.tolist())\n",
    "print(\"Community DataFrame columns:\", community_df.columns.tolist())\n",
    "if 'total_reviews' not in df.columns:\n",
    "    print(\"Warning: 'total_reviews' not found. Using uniform node sizes.\")\n",
    "if 'community_weighted' not in community_df.columns:\n",
    "    raise KeyError(\"Column 'community_weighted' not found in task7_communities.csv.\")\n",
    "\n",
    "# Step 1: Merge community data with DataFrame\n",
    "df = df.merge(community_df[['restaurant_name', 'community_weighted']], on='restaurant_name', how='left')\n",
    "print(f\"Merged DataFrame: {len(df)} rows\")\n",
    "\n",
    "# Step 2: Sample nodes proportionally by community\n",
    "sample_size = 1000\n",
    "community_counts = df['community_weighted'].value_counts()\n",
    "total_nodes = len(df)\n",
    "sample_proportions = community_counts / total_nodes\n",
    "sample_sizes = (sample_proportions * sample_size).round().astype(int)\n",
    "sample_sizes = sample_sizes[sample_sizes > 0]\n",
    "\n",
    "sampled_nodes = []\n",
    "for comm, size in sample_sizes.items():\n",
    "    comm_nodes = df[df['community_weighted'] == comm]['restaurant_name'].tolist()\n",
    "    comm_nodes = [node for node in comm_nodes if node in G.nodes()]\n",
    "    sampled = np.random.choice(comm_nodes, size=min(size, len(comm_nodes)), replace=False)\n",
    "    sampled_nodes.extend(sampled)\n",
    "\n",
    "# Ensure sample size is met\n",
    "if len(sampled_nodes) < sample_size:\n",
    "    remaining = sample_size - len(sampled_nodes)\n",
    "    other_nodes = [n for n in G.nodes() if n not in sampled_nodes]\n",
    "    sampled_nodes.extend(np.random.choice(other_nodes, size=min(remaining, len(other_nodes)), replace=False))\n",
    "\n",
    "sampled_nodes = sampled_nodes[:sample_size]\n",
    "print(f\"Sampled {len(sampled_nodes)} nodes for visualization\")\n",
    "\n",
    "# Step 3: Create sampled subgraph\n",
    "G_sample = G.subgraph(sampled_nodes)\n",
    "print(f\"Sampled subgraph: {G_sample.number_of_nodes()} nodes, {G_sample.number_of_edges()} edges\")\n",
    "\n",
    "# Step 4: Visualize the global network\n",
    "def visualize_global_network(graph, df, output_file, sample_size=1000):\n",
    "    \"\"\"Visualize the sampled global network with PyVis.\"\"\"\n",
    "    net = Network(notebook=True, height=\"800px\", width=\"100%\", directed=False, cdn_resources='in_line')\n",
    "    \n",
    "    # Define color map for communities\n",
    "    unique_communities = df['community_weighted'].dropna().unique()\n",
    "    n_communities = len(unique_communities)\n",
    "    print(f\"Number of unique communities: {n_communities}\")\n",
    "    color_map = plt.colormaps['viridis']  # Updated API for Matplotlib >= 3.7.0\n",
    "    comm_to_color = {comm: mcolors.rgb2hex(color_map(i / n_communities)) for i, comm in enumerate(unique_communities)}\n",
    "    \n",
    "    # Normalize total_reviews for node sizes (between 10 and 50)\n",
    "    if 'total_reviews_count' in df.columns:\n",
    "        reviews = df['total_reviews_count'].dropna()\n",
    "        min_reviews, max_reviews = reviews.min(), reviews.max()\n",
    "        if max_reviews > min_reviews:\n",
    "            size_scaling = lambda x: 10 + 40 * (x - min_reviews) / (max_reviews - min_reviews)\n",
    "        else:\n",
    "            size_scaling = lambda x: 20\n",
    "    else:\n",
    "        size_scaling = lambda x: 20\n",
    "    \n",
    "    # Set node properties\n",
    "    for node in graph.nodes():\n",
    "        node_row = df[df['restaurant_name'] == node]\n",
    "        if not node_row.empty:\n",
    "            comm = node_row['community_weighted'].iloc[0] if pd.notna(node_row['community_weighted'].iloc[0]) else 'unknown'\n",
    "            color = comm_to_color.get(comm, '#888888')\n",
    "            size = size_scaling(node_row['total_reviews_count'].iloc[0]) if 'total_reviews_count' in node_row.columns and pd.notna(node_row['total_reviews_count'].iloc[0]) else 20\n",
    "            title = f\"Restaurant: {node}\\nCommunity: {comm}\\nReviews: {node_row['total_reviews_count'].iloc[0] if 'total_reviews_count' in node_row.columns else 'N/A'}\"\n",
    "        else:\n",
    "            color = '#888888'\n",
    "            size = 20\n",
    "            title = f\"Restaurant: {node}\\nCommunity: unknown\\nReviews: N/A\"\n",
    "        \n",
    "        net.add_node(\n",
    "            node,\n",
    "            label=node,\n",
    "            color=color,\n",
    "            size=size,\n",
    "            title=title\n",
    "        )\n",
    "    \n",
    "    # Set edge properties\n",
    "    for edge in graph.edges(data=True):\n",
    "        weight = edge[2].get('weight', 1)\n",
    "        net.add_edge(\n",
    "            edge[0],\n",
    "            edge[1],\n",
    "            value=weight * 2,  # Scale for visibility\n",
    "            title=f\"Weight: {weight:.2f}\",\n",
    "            color='#888888'\n",
    "        )\n",
    "    \n",
    "    net.show_buttons(filter_=['physics'])\n",
    "    net.show(output_file)\n",
    "    print(f\"Visualization saved to {output_file}\")\n",
    "\n",
    "visualize_global_network(G_sample, df, \"./task10_global_network.html\")\n",
    "\n",
    "# Step 5: Save sampled nodes for reference\n",
    "sampled_df = df[df['restaurant_name'].isin(sampled_nodes)][['restaurant_name', 'community_weighted', 'total_reviews_count']]\n",
    "sampled_df.to_csv('./task10_sampled_nodes.csv', index=False)\n",
    "print(\"Saved sampled nodes to ./task10_sampled_nodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54acf39a-342d-4562-bfe1-5b4d82356961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"./task10_global_network.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb2c31a3990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "def showMyHtmlGraph(path):\n",
    "    display(IFrame(path, width=\"100%\", height=\"600px\"))\n",
    "showMyHtmlGraph(\"./task10_global_network.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23d6746-8d68-4491-8b3f-ba9eab304ed7",
   "metadata": {},
   "source": [
    "# task 11\n",
    "## Keyword Similarity Network \n",
    "- Build a separate network using similarity between keywords (e.g., using TF-IDF or cosine similarity). \n",
    "- Link restaurants with similar descriptions and analyze communities in this network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427f9004-2130-4a90-8573-cc4b1ef4ee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyvis\n",
      "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting python-louvain\n",
      "  Downloading python-louvain-0.16.tar.gz (204 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.6/204.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ipython>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from pyvis) (8.22.2)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /opt/conda/lib/python3.11/site-packages (from pyvis) (3.1.3)\n",
      "Collecting jsonpickle>=1.4.1 (from pyvis)\n",
      "  Downloading jsonpickle-4.0.5-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: networkx>=1.11 in /opt/conda/lib/python3.11/site-packages (from pyvis) (3.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from python-louvain) (1.26.4)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2>=2.9.6->pyvis) (2.1.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\n",
      "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonpickle-4.0.5-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: python-louvain\n",
      "  Building wheel for python-louvain (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-louvain: filename=python_louvain-0.16-py3-none-any.whl size=9389 sha256=241cc1d8f7d093350bb9f66721d876a582b1a0a23f27d3230492fc09bf703f9a\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/11/c1/e7/f62a211c636275e2da798bf0c307a3ae79aeddaf2524a03ce4\n",
      "Successfully built python-louvain\n",
      "Installing collected packages: python-louvain, jsonpickle, pyvis\n",
      "Successfully installed jsonpickle-4.0.5 python-louvain-0.16 pyvis-0.3.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyvis python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90ce0a86-6a0c-4ad0-9a60-ae5a6f19c58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame: 5000 rows\n",
      "DataFrame columns: ['restaurant_link', 'restaurant_name', 'original_location', 'country', 'region', 'province', 'city', 'address', 'latitude', 'longitude', 'claimed', 'awards', 'popularity_detailed', 'popularity_generic', 'top_tags', 'price_level', 'price_range', 'meals', 'cuisines', 'special_diets', 'features', 'vegetarian_friendly', 'vegan_options', 'gluten_free', 'original_open_hours', 'open_days_per_week', 'open_hours_per_week', 'working_shifts_per_week', 'avg_rating', 'total_reviews_count', 'default_language', 'reviews_count_in_default_language', 'excellent', 'very_good', 'average', 'poor', 'terrible', 'food', 'service', 'value', 'atmosphere', 'keywords']\n",
      "Sampled DataFrame: 5000 rows\n",
      "Preprocessed text data\n",
      "TF-IDF matrix shape: (5000, 138)\n",
      "Cosine similarity matrix shape: (5000, 5000)\n",
      "Similarity network: 4846 nodes, 1228947 edges\n",
      "Detected 676 communities\n",
      "\n",
      "Community Summary:\n",
      "     community  size                                       top_keywords\n",
      "0            4   890     french, european, german, friendly, vegetarian\n",
      "1            1   828  italian, pizza, friendly, vegetarian, mediterr...\n",
      "2            2   437  spanish, mediterranean, greek, friendly, veget...\n",
      "3            3     1       afghani, zealand, barbecue, bar, bangladeshi\n",
      "4          118   846         options, vegan, vegetarian, friendly, free\n",
      "..         ...   ...                                                ...\n",
      "671         47     1       afghani, zealand, barbecue, bar, bangladeshi\n",
      "672         21     1       afghani, zealand, barbecue, bar, bangladeshi\n",
      "673         23     1       afghani, zealand, barbecue, bar, bangladeshi\n",
      "674         26     1       afghani, zealand, barbecue, bar, bangladeshi\n",
      "675         27     1       afghani, zealand, barbecue, bar, bangladeshi\n",
      "\n",
      "[676 rows x 3 columns]\n",
      "Visualization subgraph: 300 nodes, 4812 edges\n",
      "./task11_similarity_network.html\n",
      "Visualization saved to ./task11_similarity_network.html\n",
      "Saved similarity graph to ./task11_similarity_graph.gml\n",
      "Saved community assignments to ./task11_communities.csv\n",
      "Saved community summary to ./task11_community_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from community import community_louvain\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_parquet('./task2_df.parquet')\n",
    "print(f\"Loaded DataFrame: {len(df)} rows\")\n",
    "\n",
    "# Verify columns\n",
    "print(\"DataFrame columns:\", df.columns.tolist())\n",
    "\n",
    "# Step 1: Prepare text data\n",
    "# Use 'special_diets' and 'cuisines' for richer text\n",
    "required_columns = ['restaurant_name', 'special_diets', 'cuisines']\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        raise KeyError(f\"Column '{col}' not found in task2_df.parquet.\")\n",
    "\n",
    "# Sample 5,000 restaurants (full dataset in this case)\n",
    "sample_size = 5000\n",
    "if len(df) > sample_size:\n",
    "    df_sample = df.sample(n=sample_size, random_state=42)\n",
    "else:\n",
    "    df_sample = df\n",
    "df_sample = df_sample.reset_index(drop=True)  # Ensure sequential indices\n",
    "print(f\"Sampled DataFrame: {len(df_sample)} rows\")\n",
    "\n",
    "# Clean and preprocess text\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    if isinstance(text, list):\n",
    "        text = \", \".join(text)\n",
    "    return str(text).lower()\n",
    "\n",
    "df_sample['text'] = df_sample[['special_diets', 'cuisines']].apply(\n",
    "    lambda x: ' '.join(x.dropna().astype(str)), axis=1\n",
    ").apply(preprocess_text)\n",
    "print(\"Preprocessed text data\")\n",
    "\n",
    "# Step 2: Compute TF-IDF and cosine similarity\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df_sample['text'])\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "print(f\"Cosine similarity matrix shape: {cosine_sim.shape}\")\n",
    "\n",
    "# Step 3: Build similarity network\n",
    "G = nx.Graph()\n",
    "similarity_threshold = 0.3  # Reduced to balance edge density\n",
    "\n",
    "# Add nodes\n",
    "for idx, row in df_sample.iterrows():\n",
    "    G.add_node(row['restaurant_name'])\n",
    "\n",
    "# Add edges\n",
    "for i in range(len(cosine_sim)):\n",
    "    for j in range(i + 1, len(cosine_sim)):\n",
    "        sim_score = cosine_sim[i, j]\n",
    "        if sim_score > similarity_threshold:\n",
    "            restaurant_i = df_sample.iloc[i]['restaurant_name']\n",
    "            restaurant_j = df_sample.iloc[j]['restaurant_name']\n",
    "            G.add_edge(restaurant_i, restaurant_j, weight=sim_score)\n",
    "\n",
    "print(f\"Similarity network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "# Step 4: Detect communities\n",
    "partition = community_louvain.best_partition(G, weight='weight', resolution=0.8, random_state=42)\n",
    "communities = {}\n",
    "for node, comm_id in partition.items():\n",
    "    if comm_id not in communities:\n",
    "        communities[comm_id] = []\n",
    "    communities[comm_id].append(node)\n",
    "\n",
    "print(f\"Detected {len(communities)} communities\")\n",
    "\n",
    "# Step 5: Analyze communities\n",
    "# Create community DataFrame\n",
    "comm_df = pd.DataFrame({\n",
    "    'restaurant_name': partition.keys(),\n",
    "    'community': partition.values()\n",
    "})\n",
    "\n",
    "# Summarize community sizes\n",
    "comm_sizes = pd.Series(partition.values()).value_counts().reset_index()\n",
    "comm_sizes.columns = ['community', 'size']\n",
    "\n",
    "# Extract top keywords per community\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "community_keywords = []\n",
    "for comm_id in communities:\n",
    "    comm_nodes = communities[comm_id]\n",
    "    # Map restaurant names to positional indices\n",
    "    comm_indices = df_sample.index[df_sample['restaurant_name'].isin(comm_nodes)].tolist()\n",
    "    if not comm_indices:\n",
    "        continue  # Skip empty communities\n",
    "    # Sum TF-IDF scores\n",
    "    comm_tfidf = tfidf_matrix[comm_indices].sum(axis=0).A1\n",
    "    # Get top 5 keywords\n",
    "    top_indices = comm_tfidf.argsort()[-5:][::-1]\n",
    "    top_keywords = [feature_names[idx] for idx in top_indices]\n",
    "    community_keywords.append({\n",
    "        'community': comm_id,\n",
    "        'size': len(comm_nodes),\n",
    "        'top_keywords': \", \".join(top_keywords)\n",
    "    })\n",
    "\n",
    "comm_summary = pd.DataFrame(community_keywords)\n",
    "print(\"\\nCommunity Summary:\")\n",
    "print(comm_summary)\n",
    "\n",
    "# Step 6: Visualize a sampled subgraph\n",
    "def visualize_similarity_network(graph, partition, df, output_file, sample_size=300):\n",
    "    \"\"\"Visualize a sampled subgraph with PyVis.\"\"\"\n",
    "    sample_nodes = list(graph.nodes())[:min(sample_size, graph.number_of_nodes())]\n",
    "    G_sample = graph.subgraph(sample_nodes)\n",
    "    print(f\"Visualization subgraph: {G_sample.number_of_nodes()} nodes, {G_sample.number_of_edges()} edges\")\n",
    "    \n",
    "    net = Network(notebook=True, height=\"600px\", width=\"100%\", directed=False, cdn_resources='in_line')\n",
    "    \n",
    "    unique_comms = set(partition.values())\n",
    "    n_comms = len(unique_comms)\n",
    "    color_map = plt.colormaps['viridis']\n",
    "    comm_to_color = {comm: mcolors.rgb2hex(color_map(i / n_comms)) for i, comm in enumerate(unique_comms)}\n",
    "    \n",
    "    for node in G_sample.nodes():\n",
    "        comm = partition.get(node, -1)\n",
    "        color = comm_to_color.get(comm, '#888888')\n",
    "        net.add_node(\n",
    "            node,\n",
    "            label=node,\n",
    "            color=color,\n",
    "            size=20,\n",
    "            title=f\"Restaurant: {node}\\nCommunity: {comm}\"\n",
    "        )\n",
    "    \n",
    "    for edge in G_sample.edges(data=True):\n",
    "        net.add_edge(\n",
    "            edge[0],\n",
    "            edge[1],\n",
    "            value=edge[2].get('weight', 1) * 2,\n",
    "            title=f\"Similarity: {edge[2].get('weight', 1):.2f}\",\n",
    "            color='#888888'\n",
    "        )\n",
    "    \n",
    "    net.show_buttons(filter_=['physics'])\n",
    "    net.show(output_file)\n",
    "    print(f\"Visualization saved to {output_file}\")\n",
    "\n",
    "visualize_similarity_network(G, partition, df_sample, \"./task11_similarity_network.html\")\n",
    "\n",
    "# Step 7: Save outputs\n",
    "nx.write_gml(G, './task11_similarity_graph.gml')\n",
    "comm_df.to_csv('./task11_communities.csv', index=False)\n",
    "comm_summary.to_csv('./task11_community_summary.csv', index=False)\n",
    "print(\"Saved similarity graph to ./task11_similarity_graph.gml\")\n",
    "print(\"Saved community assignments to ./task11_communities.csv\")\n",
    "print(\"Saved community summary to ./task11_community_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1f74c62-338d-4657-b111-390cd8226857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"./task11_similarity_network.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb2b70dffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "def showMyHtmlGraph(path):\n",
    "    display(IFrame(path, width=\"100%\", height=\"600px\"))\n",
    "showMyHtmlGraph(\"./task11_similarity_network.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3fb2ce-f6eb-4563-b564-41b4c0b741fd",
   "metadata": {},
   "source": [
    "# task12\n",
    "## Backbone Extraction \n",
    "- Use techniques like disparity filtering to extract the most informative subnetwork. \n",
    "- Analyze and visualize the resulting structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a8f5db1-867e-4a7a-aab4-76d3cbd37126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvis in /opt/conda/lib/python3.11/site-packages (0.3.2)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from pyvis) (8.22.2)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /opt/conda/lib/python3.11/site-packages (from pyvis) (3.1.3)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from pyvis) (4.0.5)\n",
      "Requirement already satisfied: networkx>=1.11 in /opt/conda/lib/python3.11/site-packages (from pyvis) (3.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2>=2.9.6->pyvis) (2.1.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Loaded graph: 4846 nodes, 1228947 edges\n",
      "Edge weight stats: min=0.3000, max=1.0000, mean=0.5121, std=0.1799\n",
      "Loaded communities: 4846 restaurants\n",
      "Loaded DataFrame: 5000 rows\n",
      "Edges before filtering: 1228947\n",
      "Edges to remove: 1147449\n",
      "Backbone graph: 4175 nodes, 528199 edges\n",
      "\n",
      "Backbone Analysis:\n",
      "            metric          value\n",
      "0        num_nodes    4175.000000\n",
      "1        num_edges  528199.000000\n",
      "2       avg_degree     253.029461\n",
      "3   num_components       2.000000\n",
      "4  avg_degree_dist     253.029461\n",
      "5  std_degree_dist     178.524334\n",
      "Visualization subgraph: 300 nodes, 2546 edges\n",
      "./task12_backbone_network.html\n",
      "Visualization saved to ./task12_backbone_network.html\n",
      "Saved backbone graph to ./task12_backbone_graph.gml\n",
      "Saved analysis to ./task12_backbone_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "\n",
    "# Install required package\n",
    "!pip install pyvis\n",
    "\n",
    "# Load Task 11 similarity graph\n",
    "G = nx.read_gml('./task11_similarity_graph.gml')\n",
    "print(f\"Loaded graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "# Debug: Check edge weight distribution\n",
    "weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "print(f\"Edge weight stats: min={min(weights):.4f}, max={max(weights):.4f}, mean={np.mean(weights):.4f}, std={np.std(weights):.4f}\")\n",
    "\n",
    "# Optionally load Task 11 communities and Task 2 DataFrame\n",
    "comm_df = None\n",
    "df = None\n",
    "# if Path('./task11_communities.csv').exists():\n",
    "comm_df = pd.read_csv('./task11_communities.csv')\n",
    "print(f\"Loaded communities: {len(comm_df)} restaurants\")\n",
    "# if Path('./task2_df.parquet').exists():\n",
    "df = pd.read_parquet('./task2_df.parquet')\n",
    "print(f\"Loaded DataFrame: {len(df)} rows\")\n",
    "\n",
    "# Step 1: Disparity filtering\n",
    "def disparity_filter(G, alpha=0.4):\n",
    "    \"\"\"Apply disparity filtering to extract the backbone.\"\"\"\n",
    "    G_backbone = G.copy()\n",
    "    edges_to_remove = []\n",
    "    \n",
    "    for node in G.nodes():\n",
    "        # Get degree and edge weights\n",
    "        degree = G.degree(node)\n",
    "        if degree <= 1:\n",
    "            continue\n",
    "        # Sum of weights for the node\n",
    "        strength = sum(G[node][neighbor]['weight'] for neighbor in G.neighbors(node))\n",
    "        # Compute normalized weights\n",
    "        for neighbor in G.neighbors(node):\n",
    "            weight = G[node][neighbor]['weight']\n",
    "            p_ij = weight / strength\n",
    "            # Disparity filter: keep edges where weight is significant\n",
    "            # Null model: integral from p_ij to 1 of (1-x)^(k-1) < alpha\n",
    "            if degree > 1:\n",
    "                integral = (1 - p_ij) ** (degree - 1)\n",
    "                if integral > alpha:\n",
    "                    edges_to_remove.append((node, neighbor))\n",
    "    \n",
    "    print(f\"Edges before filtering: {G.number_of_edges()}\")\n",
    "    print(f\"Edges to remove: {len(edges_to_remove)}\")\n",
    "    G_backbone.remove_edges_from(edges_to_remove)\n",
    "    # Remove isolated nodes\n",
    "    isolated = list(nx.isolates(G_backbone))\n",
    "    G_backbone.remove_nodes_from(isolated)\n",
    "    \n",
    "    return G_backbone\n",
    "\n",
    "alpha = 0.4\n",
    "G_backbone = disparity_filter(G, alpha)\n",
    "print(f\"Backbone graph: {G_backbone.number_of_nodes()} nodes, {G_backbone.number_of_edges()} edges\")\n",
    "\n",
    "# Check for empty backbone\n",
    "if G_backbone.number_of_nodes() == 0:\n",
    "    print(\"Warning: Backbone is empty. Try increasing alpha or checking input graph weights.\")\n",
    "\n",
    "# Step 2: Analyze the backbone\n",
    "# Compute metrics\n",
    "num_nodes = G_backbone.number_of_nodes()\n",
    "num_edges = G_backbone.number_of_edges()\n",
    "avg_degree = sum(dict(G_backbone.degree()).values()) / num_nodes if num_nodes > 0 else 0\n",
    "num_components = nx.number_connected_components(G_backbone) if num_nodes > 0 else 0\n",
    "\n",
    "# Degree distribution\n",
    "degrees = [degree for _, degree in G_backbone.degree()]\n",
    "avg_degree_dist = np.mean(degrees) if degrees else 0\n",
    "std_degree_dist = np.std(degrees) if degrees else 0\n",
    "\n",
    "# Save analysis\n",
    "analysis_data = {\n",
    "    'metric': ['num_nodes', 'num_edges', 'avg_degree', 'num_components', 'avg_degree_dist', 'std_degree_dist'],\n",
    "    'value': [num_nodes, num_edges, avg_degree, num_components, avg_degree_dist, std_degree_dist]\n",
    "}\n",
    "analysis_df = pd.DataFrame(analysis_data)\n",
    "print(\"\\nBackbone Analysis:\")\n",
    "print(analysis_df)\n",
    "\n",
    "# Step 3: Visualize the backbone\n",
    "def visualize_backbone(graph, comm_df, df, output_file, sample_size=300):\n",
    "    \"\"\"Visualize a sampled backbone subgraph with PyVis.\"\"\"\n",
    "    if graph.number_of_nodes() == 0:\n",
    "        print(\"Cannot visualize: Backbone graph is empty.\")\n",
    "        return\n",
    "    \n",
    "    # Sample nodes\n",
    "    sample_nodes = list(graph.nodes())[:min(sample_size, graph.number_of_nodes())]\n",
    "    G_sample = graph.subgraph(sample_nodes)\n",
    "    print(f\"Visualization subgraph: {G_sample.number_of_nodes()} nodes, {G_sample.number_of_edges()} edges\")\n",
    "    \n",
    "    net = Network(notebook=True, height=\"600px\", width=\"100%\", directed=False, cdn_resources='in_line')\n",
    "    \n",
    "    # Color by community if available, else by degree\n",
    "    if comm_df is not None:\n",
    "        partition = dict(zip(comm_df['restaurant_name'], comm_df['community']))\n",
    "        unique_comms = set(partition.values())\n",
    "        n_comms = len(unique_comms)\n",
    "        color_map = plt.colormaps['viridis']\n",
    "        comm_to_color = {comm: mcolors.rgb2hex(color_map(i / n_comms)) for i, comm in enumerate(unique_comms)}\n",
    "    else:\n",
    "        degrees = dict(graph.degree())\n",
    "        max_degree = max(degrees.values()) if degrees else 1\n",
    "        color_map = plt.colormaps['viridis']\n",
    "        comm_to_color = {deg: mcolors.rgb2hex(color_map(deg / max_degree)) for deg in set(degrees.values())}\n",
    "    \n",
    "    # Node size by degree\n",
    "    degrees = dict(graph.degree())\n",
    "    max_degree = max(degrees.values()) if degrees else 1\n",
    "    min_size, max_size = 10, 50\n",
    "    \n",
    "    # Node attributes\n",
    "    for node in G_sample.nodes():\n",
    "        degree = degrees.get(node, 0)\n",
    "        size = min_size + (max_size - min_size) * (degree / max_degree) if max_degree > 0 else 20\n",
    "        if comm_df is not None and node in partition:\n",
    "            color = comm_to_color.get(partition[node], '#888888')\n",
    "            title = f\"Restaurant: {node}\\nCommunity: {partition[node]}\\nDegree: {degree}\"\n",
    "        else:\n",
    "            color = comm_to_color.get(degree, '#888888')\n",
    "            title = f\"Restaurant: {node}\\nDegree: {degree}\"\n",
    "        net.add_node(\n",
    "            node,\n",
    "            label=node,\n",
    "            color=color,\n",
    "            size=size,\n",
    "            title=title\n",
    "        )\n",
    "    \n",
    "    # Edge attributes\n",
    "    for edge in G_sample.edges(data=True):\n",
    "        weight = edge[2].get('weight', 1)\n",
    "        net.add_edge(\n",
    "            edge[0],\n",
    "            edge[1],\n",
    "            value=weight * 2,\n",
    "            title=f\"Similarity: {weight:.2f}\",\n",
    "            color='#888888'\n",
    "        )\n",
    "    \n",
    "    net.show_buttons(filter_=['physics'])\n",
    "    net.show(output_file)\n",
    "    print(f\"Visualization saved to {output_file}\")\n",
    "\n",
    "visualize_backbone(G_backbone, comm_df, df, \"./task12_backbone_network.html\")\n",
    "\n",
    "# Step 4: Save outputs\n",
    "nx.write_gml(G_backbone, './task12_backbone_graph.gml')\n",
    "analysis_df.to_csv('./task12_backbone_analysis.csv', index=False)\n",
    "print(\"Saved backbone graph to ./task12_backbone_graph.gml\")\n",
    "print(\"Saved analysis to ./task12_backbone_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e52e93fd-24af-4da0-8185-4c60f73047cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"./task12_backbone_network.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9edfd3db10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "def showMyHtmlGraph(path):\n",
    "    display(IFrame(path, width=\"100%\", height=\"600px\"))\n",
    "showMyHtmlGraph(\"./task12_backbone_network.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4807d0-c86c-4eae-9661-f587305bd004",
   "metadata": {},
   "source": [
    "# task 13\n",
    "## Recommendation via Network Proximity \n",
    "- For a given restaurant, suggest similar ones based on shortest paths, common neighbors, or graph \n",
    "embeddings. \n",
    "- Evaluate how well these recommendations align with shared features or cuisines. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e30cd1b-0d13-4a67-b819-63c51f19ec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting node2vec\n",
      "  Downloading node2vec-0.5.0-py3-none-any.whl.metadata (849 bytes)\n",
      "Collecting gensim<5.0.0,>=4.3.0 (from node2vec)\n",
      "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: joblib<2.0.0,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from node2vec) (1.4.2)\n",
      "Requirement already satisfied: networkx<4.0.0,>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from node2vec) (3.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /opt/conda/lib/python3.11/site-packages (from node2vec) (1.26.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.11/site-packages (from node2vec) (4.66.4)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim<5.0.0,>=4.3.0->node2vec)\n",
      "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m222.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting smart-open>=1.8.1 (from gensim<5.0.0,>=4.3.0->node2vec)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.0->node2vec) (1.16.0)\n",
      "Downloading node2vec-0.5.0-py3-none-any.whl (7.2 kB)\n",
      "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: smart-open, scipy, gensim, node2vec\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.0\n",
      "    Uninstalling scipy-1.14.0:\n",
      "      Successfully uninstalled scipy-1.14.0\n",
      "Successfully installed gensim-4.3.3 node2vec-0.5.0 scipy-1.13.1 smart-open-7.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required package\n",
    "!pip install node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00369d-112b-467e-bc9a-1837b167553c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded backbone graph: 4175 nodes, 528199 edges\n",
      "Loaded DataFrame: 5000 rows\n",
      "Loaded communities: 4846 restaurants\n",
      "Generating Node2Vec embeddings...\n"
     ]
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "# Load graph (prefer backbone, fallback to similarity graph)\n",
    "graph_file = './task12_backbone_graph.gml'\n",
    "# if Path(graph_file).exists():\n",
    "G = nx.read_gml(graph_file)\n",
    "print(f\"Loaded backbone graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "# else:\n",
    "#     graph_file = './task11_similarity_graph.gml'\n",
    "#     G = nx.read_gml(graph_file)\n",
    "#     print(f\"Loaded similarity graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "# Check if graph is empty\n",
    "if G.number_of_nodes() == 0:\n",
    "    print(\"Error: Graph is empty. Please ensure Task 12 produced a valid graph.\")\n",
    "    exit()\n",
    "\n",
    "# Load Task 2 DataFrame for features\n",
    "df = None\n",
    "# if Path('./task2_df.parquet').exists():\n",
    "df = pd.read_parquet('./task2_df.parquet')\n",
    "print(f\"Loaded DataFrame: {len(df)} rows\")\n",
    "# else:\n",
    "#     print(\"Error: task2_df.parquet not found. Required for evaluation.\")\n",
    "#     exit()\n",
    "\n",
    "# Load Task 11 communities (optional)\n",
    "comm_df = None\n",
    "# if Path('./task11_communities.csv').exists():\n",
    "comm_df = pd.read_csv('./task11_communities.csv')\n",
    "print(f\"Loaded communities: {len(comm_df)} restaurants\")\n",
    "\n",
    "# Step 1: Generate Node2Vec embeddings\n",
    "def generate_embeddings(G, dimensions=64, walk_length=30, num_walks=200, workers=4):\n",
    "    \"\"\"Generate Node2Vec embeddings for the graph.\"\"\"\n",
    "    node2vec = Node2Vec(\n",
    "        G,\n",
    "        dimensions=dimensions,\n",
    "        walk_length=walk_length,\n",
    "        num_walks=num_walks,\n",
    "        workers=workers,\n",
    "        quiet=True\n",
    "    )\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    embeddings = {node: model.wv[node] for node in G.nodes()}\n",
    "    return embeddings\n",
    "\n",
    "print(\"Generating Node2Vec embeddings...\")\n",
    "embeddings = generate_embeddings(G)\n",
    "\n",
    "# Step 2: Recommendation functions\n",
    "def shortest_path_recommendations(G, source, top_k=5):\n",
    "    \"\"\"Recommend restaurants based on shortest path lengths.\"\"\"\n",
    "    try:\n",
    "        lengths = nx.single_source_dijkstra_path_length(G, source, weight='weight')\n",
    "        # Filter restaurants within distance 2 (avoid self and disconnected)\n",
    "        candidates = {n: 1.0 / (length + 1e-6) for n, length in lengths.items() if n != source and length <= 2}\n",
    "        # Sort by score (inverse distance)\n",
    "        sorted_candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        return [(n, score) for n, score in sorted_candidates]\n",
    "    except nx.NetworkXNoPath:\n",
    "        return []\n",
    "\n",
    "def common_neighbors_recommendations(G, source, top_k=5):\n",
    "    \"\"\"Recommend restaurants based on common neighbors (Jaccard similarity).\"\"\"\n",
    "    candidates = []\n",
    "    for node in G.nodes():\n",
    "        if node == source:\n",
    "            continue\n",
    "        # Get neighbors\n",
    "        source_neighbors = set(G.neighbors(source))\n",
    "        node_neighbors = set(G.neighbors(node))\n",
    "        # Compute Jaccard similarity\n",
    "        intersection = len(source_neighbors & node_neighbors)\n",
    "        union = len(source_neighbors | node_neighbors)\n",
    "        jaccard = intersection / union if union > 0 else 0\n",
    "        if jaccard > 0:\n",
    "            candidates.append((node, jaccard))\n",
    "    # Sort by Jaccard similarity\n",
    "    sorted_candidates = sorted(candidates, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return sorted_candidates\n",
    "\n",
    "def embedding_recommendations(embeddings, source, nodes, top_k=5):\n",
    "    \"\"\"Recommend restaurants based on embedding cosine similarity.\"\"\"\n",
    "    if source not in embeddings:\n",
    "        return []\n",
    "    source_embedding = embeddings[source].reshape(1, -1)\n",
    "    candidate_embeddings = np.array([embeddings[node] for node in nodes if node != source])\n",
    "    candidate_nodes = [node for node in nodes if node != source]\n",
    "    if not candidate_nodes:\n",
    "        return []\n",
    "    similarities = cosine_similarity(source_embedding, candidate_embeddings)[0]\n",
    "    # Sort by similarity\n",
    "    sorted_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    return [(candidate_nodes[i], similarities[i]) for i in sorted_indices]\n",
    "\n",
    "def hybrid_recommendations(G, embeddings, source, top_k=5, weights={'sp': 0.3, 'cn': 0.3, 'emb': 0.4}):\n",
    "    \"\"\"Combine recommendations from all methods.\"\"\"\n",
    "    # Get recommendations from each method\n",
    "    sp_recs = shortest_path_recommendations(G, source, top_k=top_k)\n",
    "    cn_recs = common_neighbors_recommendations(G, source, top_k=top_k)\n",
    "    emb_recs = embedding_recommendations(embeddings, source, G.nodes(), top_k=top_k)\n",
    "    \n",
    "    # Normalize scores\n",
    "    def normalize_scores(recs):\n",
    "        if not recs:\n",
    "            return recs\n",
    "        max_score = max(score for _, score in recs) if recs else 1\n",
    "        return [(n, score / max_score) for n, score in recs]\n",
    "    \n",
    "    sp_recs = normalize_scores(sp_recs)\n",
    "    cn_recs = normalize_scores(cn_recs)\n",
    "    emb_recs = normalize_scores(emb_recs)\n",
    "    \n",
    "    # Combine scores\n",
    "    score_dict = {}\n",
    "    for node, score in sp_recs:\n",
    "        score_dict[node] = score_dict.get(node, 0) + weights['sp'] * score\n",
    "    for node, score in cn_recs:\n",
    "        score_dict[node] = score_dict.get(node, 0) + weights['cn'] * score\n",
    "    for node, score in emb_recs:\n",
    "        score_dict[node] = score_dict.get(node, 0) + weights['emb'] * score\n",
    "    \n",
    "    # Sort by combined score\n",
    "    sorted_recs = sorted(score_dict.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return [(node, score, 'hybrid') for node, score in sorted_recs]\n",
    "\n",
    "# Step 3: Generate recommendations for a sample of restaurants\n",
    "sample_restaurants = list(G.nodes())[:10]  # Test with 10 restaurants\n",
    "recommendations = []\n",
    "\n",
    "print(\"Generating recommendations...\")\n",
    "for restaurant in sample_restaurants:\n",
    "    # Get recommendations from each method\n",
    "    sp_recs = [(r, s, 'shortest_path') for r, s in shortest_path_recommendations(G, restaurant)]\n",
    "    cn_recs = [(r, s, 'common_neighbors') for r, s in common_neighbors_recommendations(G, restaurant)]\n",
    "    emb_recs = [(r, s, 'embeddings') for r, s in embedding_recommendations(embeddings, restaurant, G.nodes())]\n",
    "    hybrid_recs = hybrid_recommendations(G, embeddings, restaurant)\n",
    "    \n",
    "    # Combine all recommendations\n",
    "    recommendations.extend([(restaurant, r, s, m) for r, s, m in sp_recs + cn_recs + emb_recs + hybrid_recs])\n",
    "\n",
    "# Save recommendations\n",
    "rec_df = pd.DataFrame(recommendations, columns=['restaurant', 'recommended', 'score', 'method'])\n",
    "rec_df.to_csv('./task13_recommendations.csv', index=False)\n",
    "print(\"Saved recommendations to ./task13_recommendations.csv\")\n",
    "\n",
    "# Step 4: Evaluate recommendations\n",
    "def evaluate_recommendations(rec_df, feature_df):\n",
    "    \"\"\"Evaluate recommendations based on cuisine overlap and feature similarity.\"\"\"\n",
    "    eval_results = []\n",
    "    \n",
    "    # Ensure feature_df has required columns\n",
    "    if 'cuisine' not in feature_df.columns or 'average_rating' not in feature_df.columns:\n",
    "        print(\"Warning: feature_df missing 'cuisine' or 'average_rating'. Skipping evaluation.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Group by restaurant and method\n",
    "    grouped = rec_df.groupby(['restaurant', 'method'])\n",
    "    \n",
    "    for (restaurant, method), group in grouped:\n",
    "        recommended = group['recommended'].tolist()\n",
    "        if not recommended:\n",
    "            continue\n",
    "        \n",
    "        # Get cuisine of source restaurant\n",
    "        source_row = feature_df[feature_df['restaurant_name'] == restaurant]\n",
    "        if source_row.empty:\n",
    "            continue\n",
    "        source_cuisine = source_row['cuisine'].iloc[0]\n",
    "        \n",
    "        # Cuisine overlap\n",
    "        rec_rows = feature_df[feature_df['restaurant_name'].isin(recommended)]\n",
    "        same_cuisine = rec_rows[rec_rows['cuisine'] == source_cuisine]\n",
    "        cuisine_overlap = len(same_cuisine) / len(rec_rows) if len(rec_rows) > 0 else 0\n",
    "        \n",
    "        # Feature similarity\n",
    "        numerical_features = ['average_rating', 'total_reviews_count']\n",
    "        if 'total_reviews_count' not in feature_df.columns:\n",
    "            numerical_features = ['average_rating']\n",
    "        \n",
    "        source_features = source_row[numerical_features].values\n",
    "        rec_features = rec_rows[numerical_features].values\n",
    "        if len(rec_features) > 0 and source_features.shape[0] > 0:\n",
    "            similarities = cosine_similarity(source_features, rec_features)[0]\n",
    "            avg_similarity = np.mean(similarities)\n",
    "        else:\n",
    "            avg_similarity = 0\n",
    "        \n",
    "        eval_results.append({\n",
    "            'restaurant': restaurant,\n",
    "            'method': method,\n",
    "            'cuisine_overlap': cuisine_overlap,\n",
    "            'feature_similarity': avg_similarity,\n",
    "            'num_recommendations': len(recommended)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(eval_results)\n",
    "\n",
    "# Evaluate and save\n",
    "eval_df = evaluate_recommendations(rec_df, df)\n",
    "eval_df.to_csv('./task13_evaluation.csv', index=False)\n",
    "print(\"Saved evaluation to ./task13_evaluation.csv\")\n",
    "\n",
    "# Print evaluation summary\n",
    "if not eval_df.empty:\n",
    "    print(\"\\nEvaluation Summary:\")\n",
    "    print(eval_df.groupby('method')[['cuisine_overlap', 'feature_similarity']].mean())\n",
    "else:\n",
    "    print(\"No evaluation results generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e28672-6e52-4e14-9711-9f5ee52c7387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1351301,
     "sourceId": 2246989,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7335220,
     "sourceId": 11686915,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
